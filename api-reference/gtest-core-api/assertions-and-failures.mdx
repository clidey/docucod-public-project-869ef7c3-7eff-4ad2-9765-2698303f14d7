---
title: "Assertions and Failure Handling"
description: "Describes the full suite of assertion macros such as ASSERT_*, EXPECT_*, and custom assertions. Discusses fatal vs. non-fatal failures, user-defined checks, and integration with reporting tools. Provides guidance on choosing the correct assertion for your scenario."
---

# Assertions and Failure Handling

This section details the comprehensive suite of assertion macros available in GoogleTest, such as `ASSERT_*`, `EXPECT_*`, and how to create custom assertions. We explain the fundamental distinctions between fatal and non-fatal failures, how you can define user checks, and how assertions integrate with GoogleTestâ€™s reporting tools. Additionally, you will find expert guidance on selecting the proper assertion macro for your testing scenario.

---

## Understanding Assertions in GoogleTest

Assertions are the core mechanism in GoogleTest for verifying program behavior during testing. They check if a condition holds true and report a success or failure accordingly.

### Fatal vs Non-Fatal Failures

GoogleTest provides two main categories of assertions:

- **ASSERT_*** macros produce *fatal* failures. When an `ASSERT_` macro fails, it immediately aborts the current function (typically the current test). This prevents any subsequent test code in that function from running.

- **EXPECT_*** macros produce *non-fatal* failures. When an `EXPECT_` macro fails, it reports the failure but allows the current function to continue running, enabling multiple checks in a single test.

**Choose `ASSERT_` when continued test execution after failure is meaningless or could cause crashes. Use `EXPECT_` when you want to check multiple conditions regardless of earlier failures.**

### Common Use Case

Suppose you want to verify that a pointer is not null before dereferencing it and then check a value:

```cpp
ASSERT_NE(ptr, nullptr) << "Pointer should not be null.";
EXPECT_EQ(*ptr, 42) << "Value pointed to should be 42.";
```

If `ptr` is null, the `ASSERT_NE` fails and aborts the test; the `EXPECT_EQ` is not evaluated, protecting your test from crashes.

## Key Assertion Macros

GoogleTest includes a vast variety of assertion macros. This document outlines the key categories and shows how to pick them appropriately.

### Boolean Condition Assertions

- `EXPECT_TRUE(condition)` / `ASSERT_TRUE(condition)`: verifies the condition is true.
- `EXPECT_FALSE(condition)` / `ASSERT_FALSE(condition)`: verifies the condition is false.

### Equality and Comparison Assertions

Use these for comparing values:

- `EXPECT_EQ(val1, val2)` / `ASSERT_EQ(val1, val2)`: checks `val1 == val2`.
- `EXPECT_NE(val1, val2)` / `ASSERT_NE(val1, val2)`: checks `val1 != val2`.
- `EXPECT_LT(val1, val2)` / `ASSERT_LT(val1, val2)`: `val1 < val2`.
- `EXPECT_LE(val1, val2)` / `ASSERT_LE(val1, val2)`: `val1 <= val2`.
- `EXPECT_GT(val1, val2)` / `ASSERT_GT(val1, val2)`: `val1 > val2`.
- `EXPECT_GE(val1, val2)` / `ASSERT_GE(val1, val2)`: `val1 >= val2`.

When comparing **C-strings**, use string-specific assertions:

- `EXPECT_STREQ(str1, str2)` / `ASSERT_STREQ(str1, str2)`: string content equality.
- `EXPECT_STRNE(str1, str2)` / `ASSERT_STRNE(str1, str2)`: string inequality.
- `EXPECT_STRCASEEQ(str1, str2)` / `ASSERT_STRCASEEQ(str1, str2)`: case-insensitive equality.
- `EXPECT_STRCASENE(str1, str2)` / `ASSERT_STRCASENE(str1, str2)`: case-insensitive inequality.

### Floating-Point Comparison

Due to their precision constraints, use:

- `EXPECT_FLOAT_EQ(val1, val2)` / `ASSERT_FLOAT_EQ(val1, val2)`: for `float` approximate equality.
- `EXPECT_DOUBLE_EQ(val1, val2)` / `ASSERT_DOUBLE_EQ(val1, val2)`: for `double` approximate equality.
- `EXPECT_NEAR(val1, val2, abs_error)` / `ASSERT_NEAR(val1, val2, abs_error)`: passes if `|val1 - val2| <= abs_error`.

### Exception Assertions

If exceptions are enabled, assert exception behavior with:

- `EXPECT_THROW(statement, exception_type)` / `ASSERT_THROW(statement, exception_type)`
- `EXPECT_ANY_THROW(statement)` / `ASSERT_ANY_THROW(statement)`
- `EXPECT_NO_THROW(statement)` / `ASSERT_NO_THROW(statement)`

### Explicit Success and Failure

- `SUCCEED()`: logs a success.
- `FAIL()`: generates a fatal failure and aborts the current function.
- `ADD_FAILURE()`: generates a non-fatal failure but continues the test.

### Death Assertions (verifying process termination)

- `EXPECT_DEATH(statement, matcher)` / `ASSERT_DEATH(statement, matcher)`
- `EXPECT_DEATH_IF_SUPPORTED(statement, matcher)` etc.

Use these to verify that code triggers process exit or crashes safely.

## Assertion Streaming

All assertions support streaming additional failure details using the `<<` operator:

```cpp
EXPECT_TRUE(condition) << "Additional failure details here.";
ASSERT_EQ(x, y) << "Mismatch info: x=" << x << ", y=" << y;
```

This improves the clarity of test failure messages.

## Generalized Assertions with Matchers: `EXPECT_THAT` and `ASSERT_THAT`

GoogleTest integrates with GoogleMock matchers, allowing expressive assertions on complex objects:

```cpp
EXPECT_THAT(container, Contains(42));
ASSERT_THAT(string_value, StartsWith("Error"));
```

Matchers can express complex predicates and produce detailed failure messages.

## Writing Custom Assertions

For complex checks, GoogleTest supports:

- **Predicate assertions**: `EXPECT_PRED*` and `ASSERT_PRED*` macros enable checks on predicates.
- **Predicate-format assertions**: `EXPECT_PRED_FORMAT*` and `ASSERT_PRED_FORMAT*` macros allow fully customized failure messages via predicate-formatters returning `AssertionResult`.

Use these for improved failure diagnostics beyond simple boolean checks.

## Choosing the Right Assertion

| Situation                                   | Use Assertion Type                        |
|---------------------------------------------|------------------------------------------|
| Continue test after failure                  | Non-fatal: `EXPECT_*`                    |
| Stop test immediately on failure             | Fatal: `ASSERT_*`                        |
| Verify exception thrown                       | `EXPECT_THROW` / `ASSERT_THROW`          |
| Verify condition (true/false)                 | `EXPECT_TRUE` / `ASSERT_TRUE`             |
| Compare values or objects                      | `EXPECT_EQ` / `ASSERT_EQ` or `EXPECT_THAT`|
| Check process termination                      | `EXPECT_DEATH` / `ASSERT_DEATH`          |

## Practical Examples

### Example: Basic Assertions

```cpp
TEST(MyClassTest, BasicAssertions) {
  int x = GetValue();

  // Fatal assert: If true fails, test aborts here.
  ASSERT_GT(x, 0) << "Value must be positive";

  // Non-fatal expect: test continues even if this fails.
  EXPECT_EQ(x, 42) << "Value should be 42";
}
```

### Example: Using `EXPECT_THAT` with Matchers

```cpp
#include <gmock/gmock.h>
using namespace testing;

TEST(ContainerTest, HasExpectedElements) {
  std::vector<int> v = {1, 2, 3, 4};

  EXPECT_THAT(v, Contains(3));
  EXPECT_THAT(v, ElementsAre(1, 2, 3, 4));
  EXPECT_THAT(v, Each(Gt(0)));
}
```

### Example: Death Test

```cpp
TEST(MyClassDeathTest, CrashesOnInvalidInput) {
  EXPECT_DEATH({ my_object.DoSomething(null_ptr); }, "null pointer");
}
```

### Example: Predicate Assertion

```cpp
bool IsEven(int n) { return n % 2 == 0; }

TEST(NumberTest, IsEven) {
  EXPECT_PRED1(IsEven, 4);  // passes
  EXPECT_PRED1(IsEven, 5);  // fails
}
```

## Creating Custom Assertion Messages with `ASSERT_*` and `EXPECT_*`

When your test involves multi-step verifications or complex logic, use `SCOPED_TRACE` to add context to failures in helper functions:

```cpp
void ValidateFoo(const Foo& foo) {
  SCOPED_TRACE("Validating Foo instance");
  EXPECT_EQ(foo.value, 42);
  EXPECT_TRUE(foo.IsValid());
}

TEST(FooTest, ComplexValidation) {
  Foo foo;
  // ... set up foo ...
  ValidateFoo(foo);
}
```

## Advanced Failure Handling

### Catching Failures Programmatically

Use `EXPECT_FATAL_FAILURE` or `EXPECT_NONFATAL_FAILURE` macros to verify that code generates expected failures:

```cpp
EXPECT_FATAL_FAILURE({ ASSERT_TRUE(false); }, "failed");
EXPECT_NONFATAL_FAILURE({ EXPECT_TRUE(false); }, "failed");
```

Useful for testing testing utilities.

### Skipping Tests

You can skip a test conditionally with `GTEST_SKIP()` which aborts the test but marks it as skipped, not failed:

```cpp
TEST(FooTest, SkipsIfConditionFails) {
  if (!ConditionMet()) {
    GTEST_SKIP() << "Skipping because precondition failed.";
  }
}
```

## Integrating with Reporting and Test Flow

GoogleTest assertions seamlessly integrate with reports. Failed assertions cause either test failures or aborts as expected, and details are included in XML/JSON output if enabled.

## Summary of Best Practices

- Use `EXPECT_*` assertions when you want the test to continue after failure.
- Use `ASSERT_*` assertions to guard critical requirements that must hold before continuing.
- Use streaming to add detailed failure messages.
- Utilize `EXPECT_THAT` with matchers for expressive checks on complex data.
- Use death tests to verify code causes process termination appropriately.
- Implement custom predicates or matchers for domain-specific verification.
- Employ `SCOPED_TRACE` to improve diagnostics in helper functions.
- Use mock-specific assertions from GoogleMock to thoroughly verify mock object behavior (see Mocking Reference documentation).

---

For deeper understanding of mocking and complex matchers, refer to the Mocking Reference and gMock Cheat Sheet. The distinctions between expectation macros and how they interact with test flow are detailed in the core concepts and guides sections.

---

### Additional Resources

- [GoogleTest Assertions Reference](https://github.com/google/googletest/blob/main/docs/reference/assertions.md)
- [GoogleMock Mocking Reference](https://github.com/google/googletest/blob/main/docs/reference/mocking.md)
- [GoogleMock for Dummies](https://google.github.io/googletest/gmock_for_dummies.html)
- [gMock Cheat Sheet](https://google.github.io/googletest/gmock_cheat_sheet.html)
- [Writing Custom Matchers](https://google.github.io/googletest/gmock_cook_book.html#NewMatchers)
- [Advanced Test Features](https://github.com/google/googletest/blob/main/docs/api-reference/gtest-core-api/advanced-test-features.md)

---

This documentation empowers you to precisely detect and report test failures with confidence and control over test flow, ensuring robust and maintainable unit testing in your projects.
