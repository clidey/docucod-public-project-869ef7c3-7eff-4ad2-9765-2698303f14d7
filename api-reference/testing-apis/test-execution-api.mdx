---
title: "Running and Controlling Tests"
description: "Documents the APIs and options for test discovery, execution, controlling test order, filtering, parallelism, and customizing test result reporting with event listeners. Explains integration points for test runners and tools."
---

# Running and Controlling Tests

This page details the APIs and mechanisms that GoogleTest provides for discovering, running, and controlling tests within your test binaries. It explains how to configure test execution order, apply filters to select specific tests, manage parallelism, and customize reporting behavior through event listeners. These features empower test runners, continuous integration systems, and end users to tailor test runs to their needs with precision and control.

---

## Overview

GoogleTest automatically discovers and registers all tests compiled into your test executable. Once registered, tests can be executed either all at once or selectively based on filters. Users can customize test execution in multiple ways:

- **Test filtering:** Run only tests matching specific name patterns.
- **Test sharding:** Split tests into shards to run in parallel on multiple machines or threads.
- **Test order:** Control or randomize the order in which tests execute.
- **Event listeners:** Attach components to observe test progress and report results.

This flexibility integrates seamlessly with CI systems and custom test runners.

---

## Test Discovery and Registration

GoogleTest automatically registers each test case and individual test during static initialization. Each test is uniquely identified by its test suite name and test name.

You don't need to explicitly register tests; simply write your tests with `TEST()`, `TEST_F()`, parameterized tests, or typed tests, and GoogleTest handles discovery.

---

## Running Tests

To run tests, you typically call `RUN_ALL_TESTS()` in your `main()` function after initializing GoogleTest:

```cpp
int main(int argc, char** argv) {
  ::testing::InitGoogleTest(&argc, argv);
  return RUN_ALL_TESTS();
}
```

This executes all tests and returns an exit code indicating success or failure.

For more fine-grained control, you can run tests programmatically using the internal API, but the standard flow is almost always sufficient.

---

## Controlling Test Execution

GoogleTest offers several command-line flags and programmatic options to control what tests run and in what way.

### Test Filtering

Limit test execution to specific tests using the `--gtest_filter` flag:

- Format: `--gtest_filter=PositivePatterns[-NegativePatterns]`
- Patterns can specify test suite and test name substrings.

Examples:

```shell
# Run all tests whose names start with MyTest.
--gtest_filter=MyTest.*

# Run everything except tests ending with Slow.
--gtest_filter=-*.Slow

# Run TestA and TestB only.
--gtest_filter=TestA:TestB
```

Filtering follows a simple globbing syntax, providing powerful selection capabilities.

### Test Sharding

Distribute test workloads across multiple shards for parallel execution using:

- `--gtest_total_shards=N`
- `--gtest_shuffle` (optional, to randomize test order before sharding)
- `--gtest_shard_index=M`

The runner runs tests whose shard index matches `M` (0-based). This allows you to horizontally scale your test runs across machines or build agents.

### Test Ordering

By default, GoogleTest runs tests in the order they are defined.

Use `--gtest_shuffle` to randomize test execution order, which helps detect inter-test dependencies and order-related bugs. Use `--gtest_random_seed` to specify the seed for shuffling to reproduce failures consistently.

---

## Customizing Test Execution

### Event Listeners

GoogleTest supports event listeners that receive callbacks during the test run lifecycle, enabling customized reporting and integration.

You can add or remove listeners via the `::testing::TestEventListeners` interface:

```cpp
auto& listeners = ::testing::UnitTest::GetInstance()->listeners();

// Remove the default printer.
delete listeners.Release(listeners.default_result_printer());

// Add your custom listener.
listeners.Append(new MyCustomListener);
```

Common uses include:

- Sending test progress and results to CI dashboards.
- Logging results in custom formats.
- Integration with external tools or IDEs.

### Environment and Setup Hooks

You can customize global test setup and teardown with `Environment` classes:

```cpp
class MyEnv : public ::testing::Environment {
 public:
  void SetUp() override {/* global setup */}
  void TearDown() override {/* global teardown */}
};

::testing::AddGlobalTestEnvironment(new MyEnv);
```

This allows initializing shared resources before any test runs and cleaning up afterwards.

---

## Testing Options Summary

| Option                      | Description                                   |
|-----------------------------|-----------------------------------------------|
| `--gtest_filter=pattern`     | Runs tests matching the pattern.              |
| `--gtest_shuffle`            | Randomizes test execution order.               |
| `--gtest_random_seed=seed`  | Sets seed for shuffling tests.                 |
| `--gtest_repeat=N`           | Repeats tests N times (0 means infinite).     |
| `--gtest_break_on_failure`  | Breaks into debugger on failure.               |
| `--gtest_catch_exceptions`  | Handles exceptions thrown from tests.         |
| `--gtest_list_tests`        | Lists all tests without running them.          |
| `--gtest_output=format[:path]` | Produces output in XML or JSON for CI.     |
| `--gtest_throw_on_failure`  | Causes test to throw an exception on failure. |

### Output Formats

GoogleTest supports generating test results in XML and JSON formats, useful for CI systems and reporting tools:

```shell
--gtest_output=xml:report.xml
--gtest_output=json:report.json
```

---

## Common Workflows

### Running a subset of tests

Specify `--gtest_filter` with the desired test suite or test name patterns to focus on relevant tests, speeding feedback.

### Running tests in parallel

Combine `--gtest_total_shards` and `--gtest_shard_index` with multiple test runners to distribute test load.

### Detecting flaky tests

Use `--gtest_repeat=N` and `--gtest_shuffle` to repeatedly run tests in varied orders, enabling flaky test detection.

### Integrating with CI

Customize output with `--gtest_output`, use event listeners for richer reporting, and leverage filtering and sharding to optimize CI seasons.

---

## Troubleshooting Common Issues

### Tests Not Running

- Verify tests are linked into the binary.
- Ensure test names match filter patterns.
- Check for accidental main overrides preventing `RUN_ALL_TESTS()` execution.

### Unexpected Failures Due to Order

- Use `--gtest_shuffle` with a fixed seed to mitigate order dependencies.

### Output Not Generated

- Confirm `--gtest_output` path is valid and writable.

### Parallel Runs Failing

- Ensure tests are independent and avoid shared mutable global state.

---

## Practical Tips and Best Practices

- Use filtering and sharding to reduce test cycle times.
- Use `InSequence` or `After` clauses in mocks to enforce call order.
- Capture and use test output via event listeners for flexible reports.
- Always initialize GoogleTest before running tests for proper setup.
- Avoid setting expectations after tests have started running.

---

## Related Documentation

- [Test Cases and Fixtures](./test-case-api) — for defining tests.
- [Assertions and Expectations](./assertions-api) — verifying test outcomes.
- [Using GoogleMock Effectively](../../../guides/mocking-and-advanced-testing/using-googlemock-effectively) — for mock control and sequence.
- [Integrating with Build Systems](../../../guides/test-automation-and-integration/integrating-with-build-systems) — integrating tests into your build.
- [Running Tests in Continuous Integration](../../../guides/test-automation-and-integration/running-tests-in-ci) — best practices for CI workflows.

---

## Example: Running Selected Tests With Custom Reporting

```shell
./my_test_binary --gtest_filter=Network.* --gtest_shuffle --gtest_random_seed=1234 --gtest_output=xml:network_tests.xml
```

This runs all tests under `Network` test suite, randomizes their order with a fixed seed to ensure reproducibility, and generates an XML report at `network_tests.xml`.

---

## Mermaid Diagram: Test Execution Flow

```mermaid
flowchart TD
  Init[Test executable started] --> InitGTest[::testing::InitGoogleTest()] --> Discover[Discover and register tests]
  Discover --> RunAll[RUN_ALL_TESTS()]
  RunAll --> Filter[Apply --gtest_filter]
  Filter --> Shuffle{Is --gtest_shuffle set?}
  Shuffle -- Yes --> ShuffleTests[Shuffle test order with given seed]
  Shuffle -- No --> Execute[Execute tests in order]
  Execute -->|Single Thread| ExecuteSingle[Run tests in sequence]
  Execute -->|Parallel (sharding)| Shard[Apply sharding filter]
  Shard --> ExecuteShard[Run shard of tests]
  ExecuteSingle & ExecuteShard --> Report[Report results]
  Report --> Summary[Print summary]
  Summary --> Exit[Exit with success or failure code]
```

---

## Summary

This page comprehensively describes how to run and control test execution in GoogleTest. It covers test discovery, command-line options for filtering, ordering, and sharding tests, custom event listeners for reporting, and best practices for integrating tests into CI pipelines.

---