---
title: "Assertions and Failure Handling"
description: "Dive into the rich set of built-in assertions for checking values, behaviors, and error conditions, as well as how GoogleTest distinguishes between fatal and non-fatal failures. This forms the backbone of every testâ€™s effectiveness."
---

# Assertions and Failure Handling

GoogleTest provides a rich and expressive set of built-in assertions to verify your program's behavior, making your tests precise and informative. This page dives deep into the various assertions available, how GoogleTest distinguishes between fatal and non-fatal failures, and best practices for robust test failure handling. It forms the backbone of every test's effectiveness, empowering you to catch bugs early and act decisively.

---

## Understanding Assertions: The Heart of Verification

Assertions in GoogleTest are macros used within tests to check values, behaviors, or error conditions. They evaluate expressions and report successes or failures with detailed messages. There are two major categories:

- **Fatal failures**: Generated by `ASSERT_*` and `FAIL()` macros, these abort the current function immediately, preventing further execution.
- **Non-fatal failures**: Generated by `EXPECT_*` and `ADD_FAILURE()` macros, these allow the test function to continue running despite failed checks.

This distinction lets you control test flow precisely.

### Explicit Success and Failure

GoogleTest includes assertions for explicit success and failure to control and document test outcomes independent of an expression's result.

- `SUCCEED()` generically logs success but does not affect the overall test result.
- `FAIL()` generates a fatal failure and aborts the current function.
- `ADD_FAILURE()` generates a non-fatal failure, allowing the function to continue.

Example usage:

```cpp
switch (value) {
  case 1:
    // ... some checks ...
    break;
  default:
    FAIL() << "Unexpected value: " << value;
}
```

### Custom Failure Messages

All assertions support streaming, allowing you to append detailed contextual messages to clarify failures:

```cpp
EXPECT_EQ(x.size(), y.size()) << "Vectors x and y are of unequal length";
```

This very effectively pinpoints why an assertion failed.

---

## Core Assertion Types

### Boolean Assertions

Verify simple true or false conditions.

```cpp
EXPECT_TRUE(condition);
ASSERT_FALSE(condition);
```

### Binary Comparison Assertions

Compare values using built-in relational operators. These include:

- `EXPECT_EQ`, `ASSERT_EQ` for equality (`==`)
- `EXPECT_NE`, `ASSERT_NE` for inequality (`!=`)
- `EXPECT_LT`, `ASSERT_LT` for less than (`<`)
- `EXPECT_LE`, `ASSERT_LE` for less than or equal (`<=`)
- `EXPECT_GT`, `ASSERT_GT` for greater than (`>`)
- `EXPECT_GE`, `ASSERT_GE` for greater than or equal (`>=`)

**Note:** When comparing C strings, use string-specific macros (e.g., `EXPECT_STREQ`) to compare contents, as these macros compare pointer addresses by default.

Example:

```cpp
EXPECT_EQ(expected_value, actual_value) << "Mismatch detected";
```

### String Comparison Assertions

Assertions specialized for C strings (including wide strings) to test content equality or inequality:

- `EXPECT_STREQ` / `ASSERT_STREQ`: strings are equal
- `EXPECT_STRNE` / `ASSERT_STRNE`: strings are not equal
- `EXPECT_STRCASEEQ` / `ASSERT_STRCASEEQ`: equal ignoring case
- `EXPECT_STRCASENE` / `ASSERT_STRCASENE`: not equal ignoring case

When comparing against `nullptr`, use `EXPECT_EQ(c_string, nullptr)` or `EXPECT_NE(c_string, nullptr)`.

### Floating-Point Assertions

Due to rounding and representation errors, exact equality is unreliable for floating-point values.

GoogleTest provides:

- `EXPECT_FLOAT_EQ` / `ASSERT_FLOAT_EQ` (float, compares within 4 ULPs)
- `EXPECT_DOUBLE_EQ` / `ASSERT_DOUBLE_EQ` (double, compares within 4 ULPs)
- `EXPECT_NEAR` / `ASSERT_NEAR` (float/double, within an absolute error bound)

These assertions handle special cases like infinity and NaN gracefully.

### Exception Assertions

Verify that code throws or does not throw exceptions, requiring exceptions enabled in your build.

- `EXPECT_THROW(statement, exception_type)` / `ASSERT_THROW`
- `EXPECT_NO_THROW(statement)` / `ASSERT_NO_THROW`
- `EXPECT_ANY_THROW(statement)` / `ASSERT_ANY_THROW`

Example:

```cpp
EXPECT_THROW(FunctionThatShouldThrow(), std::runtime_error);
```

### Predicate Assertions

Predicate assertions extend flexibility by verifying the result of predicates that may take 1 to 5 arguments:

- `EXPECT_PRED1`, `EXPECT_PRED2`, ..., `EXPECT_PRED5` and
- `ASSERT_PRED1`, ..., `ASSERT_PRED5`

They print the values of predicate arguments upon failure, helping to understand which inputs caused the failure.

When predicates return `testing::AssertionResult`, use `EXPECT_PRED_FORMAT*` or `ASSERT_PRED_FORMAT*` for richer, customizable failure messages.

Example:

```cpp
bool IsPrime(int n);  // returns true if prime
EXPECT_PRED1(IsPrime, n);
```

Or with a predicate formatter:

```cpp
AssertionResult AssertIsPrime(const char* expr, int n) {
  if (IsPrime(n)) return AssertionSuccess();
  return AssertionFailure() << n << " is not prime";
}
EXPECT_PRED_FORMAT1(AssertIsPrime, n);
```

---

## Failure Handling and Propagation

### Fatal vs. Non-Fatal Failures

- **Fatal failures (`ASSERT_*`, `FAIL()`)** abort the current function immediately, preventing subsequent checks in that function from running.
- **Non-fatal failures (`EXPECT_*`, `ADD_FAILURE()`)** log the failure but allow the current function to continue execution.

### Implications for Writing Tests

- Use `ASSERT_*` when a failure means continuing the test is not meaningful (e.g., accessing invalid data).
- Use `EXPECT_*` to allow multiple checks and to collect all failures in a single run.

### Propagating Fatal Failures from Subroutines

Sometimes a fatal failure inside a subroutine only aborts that subroutine, causing the calling test to continue erroneously. To handle this:

- After calling the subroutine, check `HasFatalFailure()` to decide whether to continue.

Example:

```cpp
void Subroutine() {
  ASSERT_EQ(1, value);
}

TEST(MyTest, Example) {
  Subroutine();
  if (HasFatalFailure()) return;  // Abort if subroutine failed
  // continue test
}
```

- Alternatively, register a listener throwing exceptions on fatal failures to stop the test early.

### Checking Non-Fatal Failures

To verify that a statement does not produce fatal failures, use:

- `ASSERT_NO_FATAL_FAILURE(statement);`
- `EXPECT_NO_FATAL_FAILURE(statement);`

These macros detect fatal failures in the current thread within the supplied statement.

---

## Additional Features

### Recording Test Properties

You can enrich test results by recording key-value properties to annotate tests using:

```cpp
::testing::Test::RecordProperty("key", "value");
```

These properties appear in XML and JSON test reports.

**Important:** Property keys cannot conflict with reserved XML attribute names like `name`, `time`, `status`, etc.

### Using SCOPED_TRACE for Contextual Failure Information

Add file, line, and message context to failures inside subroutines or loops:

```cpp
SCOPED_TRACE("Index = " << i);
EXPECT_EQ(value, expected);
```

When a failure occurs, the trace shows the context:

```
Google Test trace:
/path/to/file.cc:123: Index = 4
```

This helps quickly localize failures in complex test scenarios.

---

## Common Pitfalls and Best Practices

- Avoid mixing `ASSERT_*` failures and test code that proceeds without checking for failure, which can cause crashes.
- Use string-specific macros for C string comparisons to check contents, not pointer equality.
- Stream meaningful failure messages for complex conditions.
- Use `SCOPED_TRACE` liberally inside loops, nested calls, or parameterized tests for improved diagnostics.
- Use `HasFatalFailure()` after subroutine calls to propagate fatal failures correctly.

---

## Summary

GoogleTest's built-in assertions and failure handling tools provide powerful control for writing effective and maintainable tests. Making intentional choices between fatal and non-fatal assertions, using predicate and predicate-format assertions for rich error messages, and augmenting failures with contextual traces are key to productive test writing. Recording properties and understanding failure flow ensure your tests are not only correct but highly diagnosable.

---

## Example: Using Assertions Together

```cpp
TEST(VectorTest, BasicOperations) {
  std::vector<int> vec = {1, 2, 3};
  ASSERT_EQ(vec.size(), 3) << "Vector should have 3 elements";

  for (int i = 0; i < 3; ++i) {
    EXPECT_EQ(vec[i], i + 1) << "Mismatch at element " << i;
  }

  SCOPED_TRACE("After modifying vector");
  vec.push_back(4);
  ASSERT_EQ(vec.size(), 4);
  EXPECT_EQ(vec.back(), 4);
}
```

If any `ASSERT_*` fails, the rest of the test function is aborted, preventing invalid operations. `EXPECT_*` failures log errors but continue to reveal other issues.

---

## See Also

- [GoogleTest Primer](overview/introduction-value/what-is-googletest)
- [Assertions Reference](docs/reference/assertions.md)
- [Advanced GoogleTest Topics](docs/advanced.md#more-assertions)
- [SCOPED_TRACE and ScopedTrace utility](docs/reference/testing.md#SCOPED_TRACE)
- [Catching Failures for Testing GoogleTest itself](googletest/gtest_assert_by_exception_test.cc)

For detailed API descriptions, error handling, and related best practices, explore the [Testing Reference](docs/reference/testing.md) and [Assertions Reference](docs/reference/assertions.md).

---

## Navigate Next

- [Test Structure and Discovery](overview/core-concepts/test-structure-discovery)
- [Parameterized and Typed Test Patterns](overview/core-concepts/parameterized-and-typed-tests)
- [Introduction to Mocking](overview/core-concepts/mocking-basics)