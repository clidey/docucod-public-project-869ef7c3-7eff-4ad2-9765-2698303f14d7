---
title: "Running Tests and Interpreting Results"
description: "Demonstrates how to execute test binaries, read GoogleTest output, and interpret pass/fail results. Covers command-line usage and what to check if your test suite doesn't run or displays errors."
---

# Running Tests and Interpreting Results

This guide demonstrates how to execute your GoogleTest test binaries, interpret the output, and understand results to confidently verify your test suite’s behavior. It covers command-line usage, standard output interpretation, and troubleshooting common issues that prevent tests from running or reporting correctly.

---

## 1. Running Your Test Binaries

Once you have built your test executable (using CMake, Bazel, or your preferred build system), you are ready to run your tests.

### Step-by-Step Execution

<Steps>
<Step title="Locate Your Test Binary">
Find the compiled test executable; it is usually found in your build directory with a name you provided (for example, `my_tests` or `my_tests.exe`).
</Step>
<Step title="Run the Test Executable">
Open a terminal (Command Prompt on Windows, Terminal on Linux/macOS) and run your test binary directly:

```bash
./my_tests
```

On Windows:

```powershell
my_tests.exe
```

When executed, GoogleTest automatically discovers and runs all tests registered in the binary.
</Step>
<Step title="Observe the Output">
Your terminal will display the progress and results of each test, including passes, failures, and any output streams your tests generate.
</Step>
<Step title="Understand Exit Status">
The test program returns an exit code of `0` if all tests pass, or a non-zero value if any test fails.

You can check this in a Unix shell with:

```bash
echo $?
```
On Windows PowerShell:

```powershell
echo $LASTEXITCODE
```
</Step>
</Steps>

<Check>
Always **capture and check** the exit code of your test run in continuous integration systems or scripts to detect failures programmatically.
</Check>

---

## 2. GoogleTest Output Format Explained

GoogleTest outputs detailed, human-readable information about each test suite and test case. Understanding this makes debugging efficient.

### Common Components of the Output

- **Test suite and test case names**: Reported as `[ RUN      ] TestSuiteName.TestName`
- **Success message**: `[       OK ] TestSuiteName.TestName (X ms)`
- **Failure message**: Shows file, line, and failure condition
- **Summary**: At the end, a summary line indicating how many tests passed/failed

### Example Output

```plaintext
[==========] Running 3 tests from 1 test suite.
[----------] Global test environment set-up.
[----------] 3 tests from MathTest
[ RUN      ] MathTest.Addition
[       OK ] MathTest.Addition (1 ms)
[ RUN      ] MathTest.Subtraction
/path/to/test.cc:42: Failure
Expected equality of these values:
  2 - 1
  1
[  FAILED  ] MathTest.Subtraction (0 ms)
[ RUN      ] MathTest.Multiplication
[       OK ] MathTest.Multiplication (1 ms)
[----------] 3 tests from MathTest (2 ms total)
[----------] Global test environment tear-down
[==========] 3 tests from 1 test suite ran. (2 ms total)
[  PASSED  ] 2 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] MathTest.Subtraction

 1 FAILED TEST
```

### Interpretation

- Tests listed under `[  PASSED  ]` succeeded.
- Tests under `[  FAILED  ]` need investigation.
- The failure location includes the source file and line number.

---

## 3. Using Command-Line Options

GoogleTest provides multiple command-line flags to control test execution and output.

### Common Useful Flags

| Flag                  | Description                                      |
|-----------------------|------------------------------------------------|
| `--gtest_filter=PATTERN` | Runs only tests matching PATTERN (e.g. `MathTest.*`) |
| `--gtest_repeat=N`    | Runs all tests N times (useful for detecting flaky tests) |
| `--gtest_break_on_failure` | Breaks into debugger on test failure (platform-dependent) |
| `--gtest_output=xml[:PATH]`| Outputs results in XML format, optionally to a file|
| `--gtest_shuffle`     | Runs tests in random order to detect inter-test dependencies |

### Example: Running Only a Specific Test

```bash
./my_tests --gtest_filter=MathTest.Addition
```

### Debug Tip

Redirect output to a file for easier analysis:

```bash
./my_tests > test_output.log 2>&1
```

---

## 4. Understanding Test Results and Failure Types

### Pass
All assertions in the test passed without fatal or nonfatal failures.

### Nonfatal Failure
An `EXPECT_*` assertion failed, but test continued running to report more issues.

### Fatal Failure
An `ASSERT_*` assertion failed and aborted the current test immediately.

### Common Failure Scenarios

- **Assertion failed**: A test condition did not hold.
- **Unexpected exceptions or crashes**: The test code may throw exceptions or cause crashes.
- **Unsatisfied expectations in mocks**: Mocked methods did not receive expected calls.

### Interpreting Mock Failures
GoogleMock outputs messages describing:

- Unexpected calls
- Missing calls
- Excessive calls

Refer to [Mocking Reference](https://google.github.io/googletest/reference/mocking.html) for details.

---

## 5. Troubleshooting Common Issues

<AccordionGroup title="Common Issues When Running Tests">
<Accordion title="Test Binary Does Not Execute or Crashes Immediately">
- **Check that test executable is built correctly**.
- Confirm all dependencies (libraries, runtime) are available.
- Run under debugger or with verbose logging enabled.
- Review build logs for compile/link errors.
</Accordion>
<Accordion title="No Tests Are Run, Output Shows '0 Tests'">
- Ensure tests are properly registered (using `TEST()` / `TEST_F()` macros).
- Verify that `RUN_ALL_TESTS()` is called in `main()`.
- If filtering with `--gtest_filter=`, make sure the pattern matches existing tests.
</Accordion>
<Accordion title="Unexpected Test Failures or Flakiness">
- Check for shared state affecting tests.
- Use `--gtest_shuffle` and repeat runs to detect order dependencies.
- Inspect failure message details and source locations.
</Accordion>
<Accordion title="Verbose Output Isn't Showing Detailed Failures">
- Use `--gtest_verbose=info` or set the `GMOCK_FLAG_SET(verbose, "info")` programmatically.
- Increase logging verbosity to capture more diagnostic details.
</Accordion>
</AccordionGroup>

---

## 6. Sample Workflow: Running and Validating a Test

Assume you have a binary `math_tests` that includes tests for basic math functions.

<Steps>
<Step title="Run All Tests">
```bash
./math_tests
```
Watch the output to ensure tests execute and complete.
</Step>
<Step title="Filter to a Specific Test">
Run only the addition tests:

```bash
./math_tests --gtest_filter=MathTest.Addition
```
Verify that only the filtered tests run.
</Step>
<Step title="Generate XML Report">
Output test results for integration with CI:

```bash
./math_tests --gtest_output=xml:report.xml
```
You can then upload or analyze `report.xml`.
</Step>
<Step title="Analyze Failures">
If any tests fail, check the failure details including source file and line.

Open the source code at the indicated location to investigate.
</Step>
</Steps>

---

## 7. Additional Resources

- [GoogleTest Primer](https://google.github.io/googletest/primer.html): Get a comprehensive introduction to writing and running tests.
- [Writing Your First Test Case](../first-test-validation/writing-first-test-case.md): Learn how to write basic test cases.
- [Mocking Reference](https://google.github.io/googletest/reference/mocking.html): For advanced mock usage and interpreting mock failures.
- [Command-Line Flags Guide](https://google.github.io/googletest/advanced.html#running-the-tests): Complete list of options to control test runs.

---

<Tip>
Always handle the return code of your test runner correctly in scripts and CI pipelines; a non-zero exit code signals test failure.
</Tip>

<Note>
If your test binary fails to run or produce output, review your build configuration and verify all dependencies are correctly linked.
</Note>

<Warning>
Avoid calling `RUN_ALL_TESTS()` multiple times in your code—it must be called exactly once.
</Warning>
