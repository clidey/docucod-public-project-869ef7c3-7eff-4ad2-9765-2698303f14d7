---
title: "Running and Interpreting Test Results"
description: "Walks users through launching the test executable, understanding output, and using core features of the test runner. Highlights differences when running with Bazel, CMake, or manually."
---

# Running and Interpreting Test Results

This guide walks you through launching the GoogleTest executable, understanding its output, and using the core features of the test runner. It highlights differences when running tests with Bazel, CMake, or manually, helping you achieve confidence in your test executions.

---

## 1. Launching the Test Executable

Running your tests involves executing the test binary generated by your build system. Depending on how your project is built, the exact process differs:

- **Bazel**: Run the test with Bazel's test command:

  ```bash
  bazel test //path/to:your_test_target
  ```

  Bazel manages the test environment and captures test outputs for you.

- **CMake**: After building, run the test executable directly or via `ctest`:

  ```bash
  ctest -R your_test_executable
  # Or run the binary directly
  ./path/to/your_test_executable
  ```

- **Manual**: Compile and link your test code manually, then run the executable:

  ```bash
  ./your_test_executable [flags]
  ```

  Use command line flags to control test execution and output.

<Tip>
For maximum control over test execution, especially when debugging, running the executable manually is recommended.
</Tip>

## 2. Understanding the Test Runner Output

When you run your tests, GoogleTest prints detailed information about each test suite and individual tests:

- **[ RUN ]**: Marks the start of a test.
- **[       OK ]**: The test passed successfully.
- **[  FAILED ]**: The test failed.
- **[  SKIPPED ]**: The test was skipped (due to `GTEST_SKIP()` or filters).
- **Summary**: At the end, GoogleTest summarizes how many tests passed, failed, or were disabled.

Example output snippet:

```none
[==========] Running 3 tests from 1 test suite.
[----------] Global test environment set-up.
[----------] 3 tests from FactorialTest
[ RUN      ] FactorialTest.HandlesZeroInput
[       OK ] FactorialTest.HandlesZeroInput (0 ms)
[ RUN      ] FactorialTest.HandlesPositiveInput
[  FAILED  ] FactorialTest.HandlesPositiveInput (1 ms)
[ RUN      ] FactorialTest.DoesNegativeInput
[       OK ] FactorialTest.DoesNegativeInput (0 ms)
[----------] 3 tests from FactorialTest (1 ms total)
[----------] Global test environment tear-down
[==========] 3 tests from 1 test suite ran. (1 ms total)
[  PASSED  ] 2 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] FactorialTest.HandlesPositiveInput

 1 FAILED TEST
```

<Note>
Failure messages include the source file and line number of an assertion failure, making debugging straightforward.
</Note>

## 3. Using Core Features of the Test Runner

### 3.1. Command-line Flags

GoogleTest offers many flags to customize test runs. Common examples:

- `--gtest_filter=<pattern>`: Runs only tests matching the pattern.
  
  _Example:_ `--gtest_filter=FactorialTest.*` runs all tests in `FactorialTest`.

- `--gtest_repeat=N`: Repeats all selected tests N times for flakiness detection.

- `--gtest_shuffle`: Runs tests in randomized order.

- `--gtest_break_on_failure`: Stops execution and breaks into the debugger on first failure.

- `--gtest_color=[yes|no|auto]`: Controls colored output.

For a full list of flags and their descriptions, run your test executable with `--help`:

```bash
./your_test_executable --help
```

### 3.2. Skipping and Disabling Tests

- Prefix a test or test suite name with `DISABLED_` to disable it temporarily.

- To include disabled tests in runs, add the flag `--gtest_also_run_disabled_tests`.

- You can skip tests at runtime using the `GTEST_SKIP()` macro within test bodies or fixtures.

### 3.3. Running Tests in Isolation

- You can run a single test by combining filters:

  ```bash
  --gtest_filter=TestSuiteName.TestName
  ```

- This is invaluable for quick iterations and debugging specific failures.

<Tip>
Remember, test names should avoid underscores (`_`) to prevent filter confusion.
</Tip>

## 4. Interpreting Test Output Details

### 4.1. Test Statuses

Tests can be **Passed**, **Failed**, **Skipped**, or **Disabled**. The summary reflects these clearly.

### 4.2. Failure Information

When a test fails, GoogleTest prints the failing assertion's location and message, alongside the values expected and actual.

For example:

```none
/path/to/file.cc:42: Failure
Expected equality of these values:
  Factorial(3)
    Which is: 5
  6
```

### 4.3. Parameterized Test Outputs

Value- and type-parameterized tests append parameter information in their names and output, helping you identify which parameter caused a failure.

### 4.4. XML and JSON Output Reports

For integration with CI/CD pipelines, use the `--gtest_output` flag to generate machine-readable reports:

- Generate XML report:

  ```bash
  --gtest_output=xml:report.xml
  ```

- Generate JSON report:

  ```bash
  --gtest_output=json:report.json
  ```

These reports contain detailed test results and timings for further analysis.

## 5. Differences When Running with Bazel, CMake, or Manually

| Aspect               | Bazel                          | CMake                          | Manual                           |
|----------------------|--------------------------------|-------------------------------|---------------------------------|
| **Test Launch**       | `bazel test //target`           | Run via `ctest` or binary      | Run binary directly              |
| **Test Environment**  | Managed by Bazel                | Managed by CTest               | Yourself                        |
| **Output Capture**    | Captured and summarized by Bazel| Default stdout/stderr          | Direct to console               |
| **Flags Passing**     | Additional Bazel flag syntax    | Pass flags directly to binary  | Pass flags directly             |
| **Summary Reports**   | Bazel parses and reports        | CTest can parse XML reports    | Use `--gtest_output` for reports|

<Tip>
When debugging, prefer manual runs with flags for clearer visibility.
</Tip>

## 6. Common Pitfalls and Tips

- **Not calling `InitGoogleTest`** before `RUN_ALL_TESTS()` silently disables flag parsing.

- **Ignoring exit code** of your test executable results in CI failures being missed.

- **Misnaming tests with underscores** can cause filtering issues.

- **Forgetting to instantiate parameterized tests** will cause silent failures or warnings.

### Troubleshooting

| Issue                                      | Solution                                      |
|--------------------------------------------|-----------------------------------------------|
| Tests not running as expected                | Ensure `--gtest_filter` matches test names exactly; avoid underscores. |
| Test executable doesn't build/run           | Verify your build system integration matches your source files and dependencies. |
| Failures not appearing in output              | Confirm default result printer is not replaced or disabled. |
| Unexpected skipping of tests                  | Check if `GTEST_SKIP()` macro is called or filters exclude tests. |

## 7. Next Steps & Further Reading

- Explore the [Writing and Building Your First Test](getting-started/first-steps/writing-first-test) guide to start authoring tests.

- Visit [Setting Up Your Test Project](guides/getting_started/setup_project) for project integration with build tools.

- Learn about [Configuring GoogleTest](getting-started/prerequisites-installation/initial-configuration) for advanced flag usage and environment control.

- For mocking capabilities, see the [Mocking Reference](docs/reference/mocking.md).

- Dive into [Interpreting Test Results](docs/reference/testing.md) for detailed API insights.

---

For full reference and advanced topics, explore the rest of the GoogleTest documentation tree.

---