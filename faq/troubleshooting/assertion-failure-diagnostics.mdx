---
title: "How do I interpret assertion failures and test output?"
description: "Guidance on understanding test output, assertion result messages, and test summary reports. Helps users diagnose root causes from test logs and improve test clarity and feedback."
---

# How do I interpret assertion failures and test output?

Understanding the output of your tests and any assertion failures is crucial to diagnosing the root causes of issues in your code. This guide will help you interpret test output messages, understand assertion failure details, and make effective use of GoogleTest's summary reports to get clearer feedback on your tests.

---

## 1. Understanding Test Output Structure

GoogleTest produces clear, structured output for each test run, consisting of:

- **Test Case and Test Names**: Each test displays its test suite and test name, e.g., `MyTestSuite.MyTest`.
- **Test Result Status**: Indicates if the test `PASSED`, `FAILED`, or was `SKIPPED`.
- **Assertion Failures**: Detailed messages for failed assertions, including the file name, line number, and failure message.
- **Summary Lines**: A final summary showing the number of tests run, passed, failed, skipped, and disabled.

Example snippet of test output:

```none
[ RUN      ] MyTestSuite.MyTest
/path/to/source.cc:123: Failure
Expected equality of these values:
  foo
    Which is: 5
  bar
    Which is: 6
[  FAILED  ] MyTestSuite.MyTest (10 ms)
[==========] 1 test from 1 test suite ran. (10 ms total)
[  PASSED  ] 0 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] MyTestSuite.MyTest

 1 FAILED TEST
```

---

## 2. Decoding Assertion Failures

Assertion failure messages are crucial for diagnosing exactly why a test failed. GoogleTest provides rich failure messages that include:

- **Source Location**: File and line number where an assertion failed.
- **Detailed Failure Message**: Explains what was expected and what the actual result was.
- **Value Reporting**: Shows the values involved in comparison assertions.
- **Unified Diff for Strings**: When string comparison fails, a diff showing differences line-by-line may be included.

### Examples of Common Assertion Failures

- **EXPECT_EQ / ASSERT_EQ**: When comparing two values that don't match, output specifies the expected expression, actual expression, and their values.

  ```none
  Expected equality of these values:
    foo
      Which is: 5
    bar
      Which is: 6
  ```

- **EXPECT_TRUE / ASSERT_TRUE**: Shows the Boolean expression and actual value, and includes any user-streamed message.

- **EXPECT_STREQ / ASSERT_STREQ**: Indicates strings compared by value, with failure info showing the differing contents.

- **EXPECT_DEATH / ASSERT_DEATH**: Verifies that a statement causes the program to terminate as expected and provides the matched stderr output.

- **Predicate Assertions**: For complex conditions, predicate and predicate-formatter assertions print detailed messages explaining the failure.

---

## 3. Handling Multi-Argument and Predicate Format Assertions

GoogleTest supports predicates with up to 5 arguments, and predicate-formatters that provide customized failure messages.

Using these helps when simple Boolean assertions aren't descriptive enough.

Example:

```cpp
bool IsEven(int n) {
  return n % 2 == 0;
}
EXPECT_PRED1(IsEven, x);
```

For detailed error descriptions, predicate-formatter functions can be used:

```cpp
testing::AssertionResult AssertIsEven(const char* expr, int n) {
  if (n % 2 == 0) return testing::AssertionSuccess();
  return testing::AssertionFailure() << expr << " evaluates to " << n << ", which is odd.";
}
EXPECT_PRED_FORMAT1(AssertIsEven, x);
```

---

## 4. Using Failure Messages for Root Cause Diagnosis

When an assertion fails, reading the failure message carefully lets you quickly identify the root problem:

- **Look at the assertion macro used** (e.g., `EXPECT_EQ`, `ASSERT_TRUE`) to understand the intended check.
- **Review the expected vs actual values**: GoogleTest shows both expressions and their evaluated results.
- **Check any accompanying failure messages** that you stream into assertions (e.g., `<< "Additional info"`). They provide custom context.
- **Use stack traces if available**: For complex failures, GoogleTest can include stack traces to help locate the origin of failure.
- **Use `SCOPED_TRACE` to attach context**: If failures occur in helper functions, `SCOPED_TRACE` can add source info to help identify invocation context.

---

## 5. Test Summary Reports

At the end of a test run, GoogleTest prints a summary with:

- Total tests run
- Tests passed
- Tests failed (with a list of failed test names)
- Tests skipped
- Disabled tests count

This summary guides the next steps, such as focusing on failed tests for debugging.

You can also generate XML or JSON test reports for automated CI systems or further analysis using the `--gtest_output=xml:path` or `--gtest_output=json:path` flags.

---

## 6. Practical Tips & Best Practices for Interpreting Failures

- Always check the **exact source file and line number** indicated to find where the failure happened.
- Use **detailed comparison failures** to understand the difference between expected and actual values.
- When testing strings or collections, examine **diffs** to see precisely what differs.
- For **parameterized tests**, note how parameter values are shown, aiding failure context.
- **Avoid ignoring skipped or disabled tests**; understand why they aren't running.
- Employ **custom assertion macros** or predicate assertion functions for clearer, domain-specific error messages.
- Remember that `ASSERT_*` failures abort the current function, so use `ASSERT_NO_FATAL_FAILURE` if calling complex helper functions with assertions.
- Use GoogleTestâ€™s **event listeners or XML output** to obtain machine-readable test results for larger or automated workflows.

---

## 7. Troubleshooting Common Pain Points

### Assertion messages appear cryptic or minimal

- Ensure you are using expressive assertion macros suited for your tests (e.g., prefer `ASSERT_EQ` over `ASSERT_TRUE(x == y)`).
- Add custom failure messages via streaming (`<<`).
- Use predicate-formatter assertions for complex conditions.

### Unable to understand which test is failing in complex suites

- Use `SCOPED_TRACE` to add context messages within helper functions or loops.
- Review the test suite and test name prefix in failure output.

### Death tests failing unexpectedly

- Confirm death tests are named using the `*DeathTest` suffix as recommended.
- Verify expected exit codes and error messages in `EXPECT_DEATH` or `ASSERT_EXIT` macros.

### Failure messages contain stack traces but don't highlight cause

- Focus on the first failure reported; often the root cause is the earliest assertion failure.
- Review test setup and teardown failures indicated in summary.

---

## 8. Related Documentation & Further Exploration

- [Assertions Reference](../reference/assertions.md): In-depth details on all assertion macros and best practices.
- [Advanced GoogleTest Topics](../advanced.md): Covers predicate assertions, assertion placement, exception assertions, and test failure propagation.
- [Test Output and Logging](../api-reference/specialized-testing-apis/test-output-and-logging.md): Understand customizing your test output, XML/JSON reports, and event listeners.
- [Writing Clear and Effective Assertions](../guides/integration-and-best-practices/writing-effective-assertions.md): Crafting expressive test failure messages.
- [Using Predicate Assertions and Predicate Formatters](../docs/advanced.md#predicate-assertions-for-better-error-messages): For detailed control over assertion messaging.

---

Read these sections to master interpreting test failures and make your GoogleTest output a powerful ally in diagnosing issues efficiently.

---

## 9. Summary of User Flow: Interpreting an Assertion Failure

<Steps>
<Step title="Run Tests and Observe Output">
Execute your test binary and watch the console output. Passing tests show `[       OK ]`, failures show `[  FAILED  ]` with detailed messages.
</Step>
<Step title="Locate Failure Source">
Identify the failure file and line number from the failure message; this points directly to the assertion that failed.
</Step>
<Step title="Read the Failure Message">
Carefully analyze the descriptive message, expected vs actual values, and any additional user messages or diffs.
</Step>
<Step title="Use Contextual Aids">
If failure occurs in helpers or loops, check for `SCOPED_TRACE` messages to help narrow down invocation context.
</Step>
<Step title="Review Test Summary">
Look at the end summary to see which tests failed, skipped, or disabled, to focus your debugging effort.
</Step>
<Step title="Adjust Assertions for Clarity">
Use predicate or predicate-formatter assertions to improve the descriptiveness of failure messages in future runs.
</Step>
</Steps>

---

## 10. Example: Interpreting a Failure Output

Suppose your test fails with the following message:

```none
/path/to/foo_test.cc:45: Failure
Expected equality of these values:
  calculateSum(x, y)
    Which is: 9
  10
[  FAILED  ] MathTest.Addition (5 ms)
```

### Interpretation:
- Assertion failed on line 45 of `foo_test.cc`.
- `calculateSum(x, y)` returned 9, but the test expected 10.
- This points to a discrepancy in your summation logic or test parameters.
- Investigate the given line and examine the inputs `x` and `y`.

You may modify your test or implementation and re-run to validate the fix.

---

<div align="center">
##### Empowered debugging through clear, concise, and informative test output is your key to efficient development with GoogleTest.
</div>

---