---
title: "How can I address performance issues or slow tests?"
description: "Outlines approaches for profiling, reducing bottlenecks, leveraging parallel test execution (where available), and optimizing mock strategies for speedy test cycles."
---

# How Can I Address Performance Issues or Slow Tests?

Performance bottlenecks in your test suite can slow down development and reduce productivity. This page guides you through effective strategies in GoogleTest and GoogleMock to identify, profile, and mitigate test performance issues, enabling you to maintain fast and reliable test cycles.

---

## 1. Identifying Performance Bottlenecks

Before optimizing, first pinpoint which tests or test components cause delays:

- **Measure Test Duration via XML or JSON Reports**: Generate detailed test reports using the `--gtest_output=xml:` or `--gtest_output=json:` flags. These include per-test timing information helping you find slow tests.

- **Use Test Filtering**: Run subsets of tests with `--gtest_filter=` to isolate slow tests incrementally.

- **Leverage Custom Event Listeners**: Implement a [Test Event Listener](docs/advanced.md#extending-googletest-by-handling-test-events) to log test start and end times to measure individual test durations precisely.

- **Profiling Test Code**: Use external profilers (e.g., `perf`, Visual Studio Profiler) on your test executables to identify hotspots.

<Tip>
Generating an XML or JSON report is a simple and quick way to identify the slowest tests in your suite. Run your tests with:

```
./your_test_binary --gtest_output=xml:report.xml
```

Then examine the `time` attribute on each `<testcase>` element.
</Tip>

## 2. Optimizing Test Execution

Once you know what tests are slow, apply the following strategies to improve test performance.

### a) Run Tests in Parallel Where Available

- Use test sharding with the environment variables `GTEST_TOTAL_SHARDS` and `GTEST_SHARD_INDEX` to distribute tests across multiple machines or cores. GoogleTest will partition tests accordingly.
- Alternatively, run multiple test executables in parallel if your project is split accordingly.

<Info>
Parallel test execution can dramatically reduce feedback time but requires tests to be independent and thread-safe.
</Info>

### b) Reduce Expensive Setup and Tear-down

- Use per-test-suite `SetUpTestSuite()` and `TearDownTestSuite()` to share expensive resources among tests rather than recreate them repeatedly (see [docs/advanced.md#sharing-resources-between-tests-in-the-same-test-suite]).
- Cache commonly used data or mock objects where possible.

### c) Mock Smartly

- Use `ON_CALL()` to define common default call behavior without strict expectations, avoiding unnecessary overhead.
- Minimize `EXPECT_CALL()` usage to essential interactions only, as setting excessive expectations may slow tests.
- Use `NiceMock` to suppress warnings about uninteresting calls instead of `NaggyMock` or `StrictMock`, which can increase logging and slow down execution.

<Note>
Expectations add verification overhead. Only verify behavior critical to the test's goals.
</Note>

### d) Avoid Overly Complex Matchers or Actions

- Complex matchers or actions that involve heavy computation may slow mock call dispatch.
- Simplify matchers or use custom lightweight matchers when performance is critical.

### e) Optimize Test Data

- Use minimal but representative test data.
- Avoid large datasets unless necessary.

## 3. Profiling and Measuring Progress

- Use `--gtest_repeat=N` and rerun to measure stability and isolate intermittent slowdowns.
- Combine with `--gtest_shuffle` to surface flaky tests causing delays.
- Integrate timing measurement in your CI to track test performance over time.

## 4. Common Pitfalls and Best Practices

### Pitfall: Tests Dependent on Slow External Resources

- Avoid live network calls, database access, or filesystem I/O by mocking or faking such dependencies.

### Pitfall: Poor Mock Usage Increases Runtime

- Overusing `EXPECT_CALL` or overly detailed matchers can cause slow mock execution.
- Use coarse-grained matchers like `_` or simplified actions when possible.

### Best Practice: Reuse Mock Objects

- Define mock behaviors in shared fixtures or setup functions to reduce redundant initialization.

### Best Practice: Segment Tests by Execution Time

- Group slow, integration-style tests separately from fast unit tests.
- Run fast tests frequently; run slow tests overnight or in dedicated jobs.

## 5. Advanced Techniques

### Using GoogleMock Strictness Controls

- `NiceMock` suppresses warnings and can improve performance in large mock-heavy tests.
- `StrictMock` treats unexpected calls as failures and may slow down tests due to extra verification.

### Use `RetiresOnSaturation()` Judiciously

- Helps in scenarios where multiple expectations might otherwise conflict, avoiding unnecessary failures and retries.

### Sequence and Ordering Constraints

- Apply ordering only where needed, as sequences add verification overhead.

## 6. Diagnostic Tips

- If a test unexpectedly slows down:
  1. Check for excessive logging or debug output.
  2. Profile test code to find hotspots.
  3. Review mock expectations and matchers for complexity.
  4. Check for resource leaks or blocking calls.

<Tip>
Profiling is your best friend. Try to profile the test binary with CPU and memory profilers to identify bottlenecks quickly.
</Tip>

---

## Related Resources

- [Build System Integration and Performance Optimization](guides/integration-and-best-practices/performance-and-scalability.md)
- [Using Mocks in Tests](guides/core-testing-workflows/using-mocks-in-tests.md)
- [Mock Strictness Controls](api-reference/mocking-api/strictness-controls.md)
- [Writing Efficient Expectations](gmock_cook_book.md#knowing-when-to-expect-useoncall)
- [Generating Test Reports](docs/advanced.md#running-test-programs-advanced-options)

---

For the most comprehensive guidance, continuously monitor your test suite timing, and keep your mocks minimal and effective to sustain speedy test execution throughout development.

---

## Example: Enable Parallel Sharding of Tests

```shell
export GTEST_TOTAL_SHARDS=4
export GTEST_SHARD_INDEX=0  # For machine 1
./your_test_binary &
export GTEST_SHARD_INDEX=1  # For machine 2
./your_test_binary &
export GTEST_SHARD_INDEX=2  # For machine 3
./your_test_binary &
export GTEST_SHARD_INDEX=3  # For machine 4
./your_test_binary &
wait
```

This runs your tests split in 4 partitions across machines or processes.

---

## Example: Defining Shared Test Setup to Improve Test Speed

```cpp
class ExpensiveTestSuite : public ::testing::Test {
 protected:
  static void SetUpTestSuite() {
    resource_ = LoadExpensiveResource();
  }

  static void TearDownTestSuite() {
    ReleaseExpensiveResource(resource_);
    resource_ = nullptr;
  }

  // Pointer shared among all tests.
  static ExpensiveResource* resource_;
};

ExpensiveResource* ExpensiveTestSuite::resource_ = nullptr;

TEST_F(ExpensiveTestSuite, TestA) {
  ASSERT_TRUE(resource_ != nullptr);
  ...
}

TEST_F(ExpensiveTestSuite, TestB) {
  ASSERT_TRUE(resource_ != nullptr);
  ...
}
```

This avoids recreating the expensive resource per test, speeding up test execution.
