---
title: "Debugging Test Failures and Flaky Tests"
description: "Learn strategies for diagnosing and resolving test failures, debugging crashes, and chasing flaky or inconsistent outcomes. Provides tips for leveraging assertion output, logs, and test isolation."
---

# Debugging Test Failures and Flaky Tests

GoogleTest is a powerful C++ testing framework designed to give you clear insight into the behavior of your code. When tests fail or produce inconsistent (flaky) results, understanding the root causes is essential for reliable test suites and stable builds. This documentation page guides you through strategies for diagnosing test failures, handling crashes, and chasing flaky or intermittent test issues.

---

## 1. Understanding Test Failures

### 1.1 Types of Test Failures

- **Fatal Failures**: Triggered by `ASSERT_*` and `FAIL()` macros. These abort the current function immediately. For example, `ASSERT_EQ(x, y)` causes the test function to stop if the assertion fails.

- **Nonfatal Failures**: Triggered by `EXPECT_*` and `ADD_FAILURE()`. Execution continues after these, allowing multiple failures to be reported within the same test.

- **Test Skips**: Using `GTEST_SKIP()`, you can programmatically skip tests based on runtime conditions.

### 1.2 Interpreting Failure Messages

Every failure includes detailed messages: the source file and line, expressions involved, and an optional user-provided message. GoogleTest also attempts to show actual vs expected values including diffs for strings or containers.

```cpp
EXPECT_EQ(foo, bar) << "Check foo and bar equality";
```

When this fails, the output surfaces critical information about the failure location and why it failed.

### 1.3 Getting More Context: Using `SCOPED_TRACE`

When failures occur deep inside helper functions called repeatedly, it can be hard to know from which call site the failure originated. Use `SCOPED_TRACE(message)` to add contextual traces to failure messages:

```cpp
void Helper(int i) {
  SCOPED_TRACE(testing::Message() << "Iteration " << i);
  EXPECT_TRUE(SomeCondition());
}

TEST(MyTestSuite, Works) {
  for (int i = 0; i < 5; ++i) {
    Helper(i);
  }
}
```

Failures inside `Helper` then report which iteration they belong to.

---

## 2. Diagnosing Crashes and Fatal Failures

### 2.1 Using Assertion Macros Correctly

- Fatal assertion macros (`ASSERT_*` and `FAIL()`) must only be used in `void`-returning functions.
- Avoid returning values inside statements expected to fail fatally.
- Consider splitting complex logic into functions where assertions can be placed sensibly.

### 2.2 Checking for Fatal Failures in Subroutines

GoogleTest doesn’t propagate fatal failures like exceptions. If a fatal failure happens inside a function, that function returns early but the calling test continues executing.

To catch this, check `HasFatalFailure()` after such calls:

```cpp
void Subroutine() {
  ASSERT_EQ(1, 2);
  // Control will return here before caller notices.
}

TEST(FooTest, Bar) {
  Subroutine();
  if (HasFatalFailure()) return;
  // Rest of test...
}
```

Or use `ASSERT_NO_FATAL_FAILURE(statement)` which asserts that `statement` does not produce fatal failures.

### 2.3 Turning Failures into Exceptions

For some test frameworks or debugging scenarios, you may want fatal failures to throw exceptions. You can add a listener that throws on fatal failures:

```cpp
class ThrowOnFailureListener : public testing::EmptyTestEventListener {
  void OnTestPartResult(const testing::TestPartResult& result) override {
    if (result.type() == testing::TestPartResult::kFatalFailure) {
      throw testing::AssertionException(result);
    }
  }
};

int main(int argc, char** argv) {
  testing::InitGoogleTest(&argc, argv);
  testing::UnitTest::GetInstance()->listeners().Append(new ThrowOnFailureListener);
  return RUN_ALL_TESTS();
}
```

---

## 3. Investigating Flaky Tests

### 3.1 What Are Flaky Tests?

Flaky tests are tests that unpredictably pass or fail without code changes. They often stem from dependencies on external states, timing issues, or test order dependencies.

### 3.2 Strategies to Tackle Flakiness

- **Repeat Tests:** Use `--gtest_repeat=N` to run tests multiple times to increase failure reproduction chances.
- **Randomize Test Order:** Use `--gtest_shuffle` and observe the random seed printed to reproduce order-related issues.
- **Use `SCOPED_TRACE` with loops:** Helps identify which iteration or input caused failure.
- **Check for Shared State or Side Effects:** Avoid global states altered by tests, or ensure proper cleanup.

### 3.3 Test Isolation Tips

- Each test runs in a fresh fixture instance to avoid state leakage.
- Use `SetUpTestSuite()` and `TearDownTestSuite()` only for truly shared, read-only or stateless resources.
- Avoid dependencies between tests (no test should depend on the outcome of another).

---

## 4. Capturing Assertion Failures in Test Code

### 4.1 Testing That a Statement Fails

When writing tests to check your own test helpers or GoogleTest extensions, you often want to assert that a statement produces a failure. Use the macros:

- `EXPECT_FATAL_FAILURE(statement, "message substring")`
- `EXPECT_NONFATAL_FAILURE(statement, "message substring")`

These verify that the statement triggers exactly one fatal/nonfatal failure whose message contains the specified substring.

For example:

```cpp
EXPECT_FATAL_FAILURE(ASSERT_EQ(1, 2), "Expected equality of these values");
```

### 4.2 Catching Failures in Multithreaded Code

GoogleTest also provides `_ON_ALL_THREADS` versions:

- `EXPECT_FATAL_FAILURE_ON_ALL_THREADS`
- `EXPECT_NONFATAL_FAILURE_ON_ALL_THREADS`

to catch failures occurring in other threads.

**Note**: Local variables cannot be used inside these macros due to macro expansion limits.

---

## 5. Using Test Properties and Logs for Diagnosis

### 5.1 Recording Additional Test Properties

Use `RecordProperty("key", value)` inside tests or fixtures to log extra data that gets included in the XML output.

For example:

```cpp
TEST(MyTest, LogsProperties) {
  RecordProperty("MyKey", 42);
  EXPECT_TRUE(DoWork());
}
```

These properties help correlate failures with additional context.

### 5.2 Streaming Messages in Assertions

Custom failure messages can be streamed into any assertion using `<<`:

```cpp
EXPECT_EQ(1, result) << "Returned unexpected value for input: " << input_data;
```

They help pinpoint failure scenarios without extra print statements.

---

## 6. Debugging Workflow Summary

<Steps>
<Step title="Run Tests with Detailed Output">
Use GoogleTest’s default or verbose output to spot failing tests and review assertion messages including file and line information.
</Step>
<Step title="Re-run Failing Test only">
Run tests matching the filter for targeted debugging: `--gtest_filter=TestSuiteName.TestName`
</Step>
<Step title="Add SCOPED_TRACE for Context">
Wrap suspicious code blocks or loop iterations with `SCOPED_TRACE` to identify exact cause points.
</Step>
<Step title="Repeat and Shuffle to Reproduce">
Use `--gtest_repeat` and `--gtest_shuffle` with the printed seed to identify flaky tests.
</Step>
<Step title="Record Properties for Additional Info">
Add `RecordProperty` calls to track variables, thresholds, or conditions leading to failure.
</Step>
<Step title="Catching Failures in Helpers">
Use `EXPECT_FATAL_FAILURE` or analogous macros in test utilities to ensure proper failure reporting.
</Step>
<Step title="Enable Break-on-Failure or Exceptions">
Use `--gtest_break_on_failure` or add a listener throwing on failures to pause in debugger or propagate exceptions.
</Step>
</Steps>

---

## 7. Common Pitfalls and Best Practices

- **Fatal Assertions in Non-Void Functions:** Don’t place `ASSERT_*` in functions returning a value.
- **Mixing Test Fixtures:** Tests in the same suite must use the same fixture class; mixing `TEST` and `TEST_F` or different fixtures causes unexpected failures.
- **Dangling References in Parameterized Tests:** When using `INSTANTIATE_TEST_SUITE_P` with lambdas/functors, capture parameters carefully.
- **Avoiding Test Ordering Dependencies:** Tests must be independent and fully isolated.
- **Clearing Test Results in Long-Running Loops:** Protect against stale state causing false failures.

---

## 8. Getting More Help

- Consult the [Testing Reference](../reference/testing.md) for detailed API information.
- Use [Effective Assertions and Matchers](../guides/testing-patterns/effective-assertions.mdx) for advanced assertion techniques.
- Review test output validation examples in `googletest-output-test_.cc`.
- Join community forums or the GoogleTest GitHub repository discussions for support.

---

For a broader context on writing robust tests, explore the [Structuring and Organizing Tests](../guides/testing-patterns/structuring-tests.mdx) and [Mocking Best Practices](../guides/testing-patterns/mocking-best-practices.mdx).

---

**Example: Using `EXPECT_FATAL_FAILURE` to test a failing assertion**

```cpp
#include "gtest/gtest-spi.h"

TEST(MyInternalTest, FailsWhenValueIsIncorrect) {
  EXPECT_FATAL_FAILURE(
    ASSERT_EQ(0, 1),
    "Expected equality of these values"
  );
}
```

This test verifies that `ASSERT_EQ(0,1)` generates a fatal failure with the expected message.

---

**Example: Repeating and Shuffling Tests to Catch Flakes**

```shell
./my_tests --gtest_repeat=100 --gtest_shuffle
```

Watch output for the random seed, rerun with `--gtest_random_seed=XYZ` to reproduce.

---