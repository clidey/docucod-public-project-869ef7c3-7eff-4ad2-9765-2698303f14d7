---
title: "Diagnosing Test Failures"
description: "Practical tips for interpreting failure messages, understanding the test output, and debugging why tests fail. Includes strategies for distinguishing between fatal and non-fatal failures and using advanced output features."
---

# Diagnosing Test Failures

Efficiently diagnosing test failures is critical to maintaining high-quality software and accelerating debugging. This guide helps you interpret GoogleTest failure messages, distinguish failure types, utilize advanced output features, and apply practical strategies to uncover root causes.

---

## Understanding Failure Messages

When a test fails, GoogleTest provides detailed messages to help you pinpoint the issue swiftly.

- **Test Suite and Test Name**: Failures are reported with the test suite and test names, for example `FooTest.DoesAbc`.
- **Failure Type**:
  - *Fatal Failure* (from `ASSERT_*` or `FAIL()`): Aborts the current test function immediately.
  - *Non-fatal Failure* (from `EXPECT_*` or `ADD_FAILURE()`): Allows the test to continue, but marks it as failed.
- **Failure Location**: Reports the source file and line number where the assertion failed.
- **Failure Description**: Explains what was expected and what was actually observed.
- **Stack Trace**: Provides a call stack to identify the failure origin in your code, if enabled.

### Example Failure Message

```none
path/to/my_test.cc:42: Failure
Expected equality of these values:
  expected_value
  actual_value
...
Stack trace:
  ... call stack info ...
```

This message tells you:
- The file and line: `my_test.cc:42`
- The type of check: an equality comparison
- Values involved: expected vs actual
- Stack trace to help locate the failure context

## Distinguishing Fatal and Non-fatal Failures

Understanding these helps you decide how to handle failures and adjust test design:

- **Fatal Failures** (`ASSERT_*`, `FAIL()`) skip subsequent lines in the same test function, making them suitable when continuing doesn't make sense. However, a fatal failure does *not* abort the entire test suite or program.

- **Non-fatal Failures** (`EXPECT_*`, `ADD_FAILURE()`) report failures but continue execution, so multiple failures in a test can be reported.

*Tip:* Use fatal assertions when a failure invalidates further checks; use non-fatal assertions when you want to accumulate failures for comprehensive reports.

## Using SCOPED_TRACE to Enhance Failure Context

Failures deep in helper functions can be hard to diagnose. `SCOPED_TRACE` adds contextual trace messages that appear in failure reports.

```cpp
void Helper(int x) {
  SCOPED_TRACE("Inside Helper with x=" << x);
  EXPECT_EQ(x, 5);
}

TEST(MyTest, Example) {
  Helper(4);  // Failure message will include the trace from Helper
}
```

This enriches failure messages helping you identify which call path led to the failure.

## Interpreting Stack Traces

Stack traces help you locate the exact call sequence causing the failure.

- GoogleTest prints stack traces by default if supported and enabled via flags.
- You can configure the depth with the `--gtest_stack_trace_depth` flag.
- Internal GoogleTest frames are usually elided for clarity.

### Practical Tips

- Follow the earliest frames (closest to the test code) to locate failure.
- Use a debugger with stack trace info for pause and inspection.

## Advanced Failure Output Features

GoogleTest supports additional diagnostic outputs that can help in complex scenarios.

### XML and JSON Test Reports

- Use the `--gtest_output=xml:filename.xml` or `--gtest_output=json:file.json` flag to generate machine-readable reports.
- These reports include detailed information on failures and can be integrated into CI dashboards.

### Filtering and Re-running Failed Tests

- Use `--gtest_filter=TestSuite.TestName` to run specific tests or subsets.
- Inspect failure lists at the end of runs to identify tests to re-run.

### Colored Output

- The `--gtest_color=yes|no|auto` flag controls terminal colorization of output.
- Colors highlight failures and successes for quick scanning.

## Practical Troubleshooting Workflows

### 1. Identify Failure Location

Look for the file, test suite, and test name in the failure message.

### 2. Understand the Assertion

Read the failure message to understand the expected vs actual values.

### 3. Use Traces and Stack

Look at `SCOPED_TRACE` messages and stack traces to understand execution paths.

### 4. Run Tests in Isolation

Run individual failing tests with `--gtest_filter=TestSuite.TestName` to reproduce.

### 5. Use Debugger

Place breakpoints at failure location, or use `--gtest_break_on_failure` to automatically break on assertion failures.

### 6. Adjust and Iterate

Fix code or test, rerun, and iterate until the failure is resolved.

## Common Pitfalls and How To Avoid Them

- **Mixing `TEST` and `TEST_F` in the same test suite**: This is disallowed and will cause runtime errors. Ensure all tests in a suite use the same fixture.

- **Test names with underscores (`_`)**: Avoid underscores in test suite or test names to prevent naming conflicts and linker issues.

- **Ignoring return value of `RUN_ALL_TESTS()`**: Always return its value from `main()`; ignoring it leads to incorrect test status reporting.

- **Assertions that generate fatal failures in non-void functions or constructors/destructors**: Fatal assertions must be in void functions. Use `SetUp()`/`TearDown()` instead of constructors/destructors for fatal assertions.

- **State modified in death tests is lost**: Since death tests run in subprocesses, side effects arenâ€™t visible in the parent process.

## Useful Flags and Environment Variables

| Flag                             | Purpose                                                    |
|---------------------------------|------------------------------------------------------------|
| `--gtest_filter`                | Run subset of tests by filter                              |
| `--gtest_repeat=N`              | Repeat tests N times (negative repeats forever)           |
| `--gtest_shuffle`               | Run tests in random order                                  |
| `--gtest_break_on_failure`      | Break into debugger upon failure                           |
| `--gtest_stack_trace_depth=N`   | Set max stack trace frames printed on failure             |
| `--gtest_output=xml:PATH`       | Generate XML report                                        |
| `--gtest_output=json:PATH`      | Generate JSON report                                       |
| `--gtest_also_run_disabled_tests` | Include disabled tests in run                              |

## Using Event Listeners for Custom Diagnostics

If GoogleTest's default output is insufficient, you can augment it by creating your own event listener by subclassing `testing::TestEventListener` or extending `testing::EmptyTestEventListener`:

```cpp
class MyListener : public testing::EmptyTestEventListener {
  void OnTestPartResult(const testing::TestPartResult& result) override {
    if (result.failed()) {
      // Custom handling, e.g., output to log or gather stats
    }
  }
};

int main(int argc, char** argv) {
  testing::InitGoogleTest(&argc, argv);
  testing::UnitTest::GetInstance()->listeners().Append(new MyListener);
  return RUN_ALL_TESTS();
}
```

This lets you tailor test failure reporting to your workflow.

## Additional Resources

- [Assertions Reference](reference/assertions.md): Detailed explanations and examples of assertions.
- [GoogleTest Primer](primer.md): Starting points and fundamental concepts.
- [Advanced Topics](advanced.md): For deeper features including parameterized tests and fixtures.
- [GoogleTest FAQ](faq.md): Answers to frequent questions and common issues.

---

# Troubleshooting Checklist

- Ensure your test names and suites conform to naming rules.
- Use `--gtest_list_tests` to discover available tests.
- Run failing tests in isolation via filters.
- Use `SCOPED_TRACE` in helper functions to clarify failure context.
- Check for mixing `TEST` and `TEST_F` in the same suite.
- Use `--gtest_break_on_failure` to catch the debugger at failures.
- Inspect generated XML/JSON outputs for CI integration.


---

Empower yourself with these practices to diagnose failures efficiently, improve test robustness, and maintain a clean codebase.

---

### Reference
- GoogleTest [Advanced Topics](advanced.md#assertion-placement)
- GoogleTest [Primer](primer.md)
- GoogleTest [Assertions Reference](reference/assertions.md)
- GoogleTest [FAQ](faq.md)
- GoogleTest [Test Discovery and Execution](guides/essential-testing-patterns/test-discovery-execution.mdx)

---

