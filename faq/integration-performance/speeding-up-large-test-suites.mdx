---
title: "How Can I Speed Up Large Test Suites?"
description: "Shares performance optimization strategies, such as parallel execution, test filtering, and leveraging external tools, to help users reduce test latency and maximize CI effectiveness."
---

# How Can I Speed Up Large Test Suites?

Optimizing the performance of large test suites is critical for maintaining efficient development and continuous integration processes. Long-running test suites can slow down feedback cycles and reduce developer productivity. This guide provides actionable strategies to accelerate test execution, minimize test latency, and maximize your CI effectiveness.

---

## 1. Parallel Execution

### Why Parallelism Matters

Running tests sequentially wastes valuable CPU and I/O resources, especially on multicore machines commonly used in modern development environments.

### How to Enable Parallel Test Runs

- **Use Test Sharding**: GoogleTest supports test sharding which splits the test runs across multiple machines or processes. Configure the following environment variables for each shard:
  - `GTEST_TOTAL_SHARDS`: total number of shards (processes or machines).
  - `GTEST_SHARD_INDEX`: index of the current shard (0-based).

  This ensures each shard runs a distinct subset of tests, parallelizing across multiple executors.

- **Run Tests in Parallel Locally**: Use external tools such as:

  - [`gtest-parallel`](https://github.com/google/gtest-parallel): Runs tests from your binary in parallel processes.
  - CI systems that support parallel jobs (e.g., GitHub Actions matrix, Jenkins parallel stages).

### Best Practices

- Ensure tests are **independent and isolated** so they can safely run concurrently.
- Avoid shared global state or use proper synchronization mechanisms.

---

## 2. Test Filtering

### Selectively Run Tests

Running the entire suite for every minor change is inefficient. Use filtering to run only relevant tests.

- **Command-line Filtering**: Use the `--gtest_filter` flag to run specific tests or test suites.

```bash
./my_tests --gtest_filter=MyTestSuite.*
```

- **Run Only Failed/Changed Tests**: Integrate tools that track test results or code coverage to re-run only affected tests.

### Combining Filtering with Parallelism

Filtering helps reduce the volume of tests per shard, making parallel runs more efficient and focused.

---

## 3. Optimizing Test Fixtures and Setup

### Reuse Expensive Resources

Reduce overhead by sharing expensive setups across tests where possible:

- Use `SetUpTestSuite()` and `TearDownTestSuite()` static methods to allocate and release shared resources once per test suite.
- Minimize per-test `SetUp()` and `TearDown()` costs.

### Avoid Heavy Global Fixtures

Global fixtures (`Environment` objects) can add overhead across all tests. Use them judiciously and keep their setup lightweight.

---

## 4. Use Efficient Assertions and Avoid Flaky Tests

- Prefer `EXPECT_*` assertions to allow multiple failures in one run, preventing reruns due to early aborts.
- Mark flaky tests with `DISABLED_` prefix temporarily, addressing them later.
- Use `GTEST_SKIP()` in setup to bypass tests under unsuitable conditions instead of running and failing them.

---

## 5. Leverage External Caching and Tools

- **Test Results Caching**: Use caching systems (e.g. Bazel cache, ccache) to avoid re-running unchanged tests.
- **Continuous Integration (CI) Tuning**: Configure CI pipelines to run tests intelligently:
  - Split tests by priority (smoke tests faster, nightly full runs).
  - Parallelize across multiple agents/nodes.

- **Profile Tests**: Identify slowest tests using `--gtest_print_time=1` or CI reports to focus optimization efforts.

---

## 6. Summary of Strategies

| Strategy                     | Description                                    | Usage Tip                                   |
|------------------------------|------------------------------------------------|---------------------------------------------|
| Parallel Execution           | Run tests concurrently to utilize resources    | Use test sharding and gtest-parallel        |
| Test Filtering               | Run subsets of tests relevant to changes       | Use `--gtest_filter`                         |
| Shared Fixtures Setup       | Minimize per-test setup costs                    | Use `SetUpTestSuite` for shared expensive resources |
| Efficient Assertions & Marking | Avoid flaky tests and excessive failures       | Use `EXPECT_*`, skip unsuitable tests       |
| External Caching & CI Optimization | Use builds and cache tools to reduce reruns | Leverage caching and CI parallelism          |

---

## 7. Additional Resources

- [Running Tests in Parallel](../advanced.md#running-tests-in-parallel) (Advanced Guide)
- [gtest-parallel Project](https://github.com/google/gtest-parallel)
- [Test Filtering Usage](reference/testing.md#running-a-subset-of-the-tests)
- [Test Fixture Lifecycle](api-reference/testing-core/test-fixture-lifecycle.md)
- [GoogleTest Primer - Basic Concepts](docs/primer.md)

---

<Tip>
Balancing test speed and thoroughness is key. Start by identifying your slowest tests and either optimize or isolate them. Harness parallel execution and filtering to shorten feedback cycles without sacrificing coverage.
</Tip>

<Note>
Avoid assumptions of test independence when enabling parallel runs to prevent race conditions and flaky false failures.
</Note>

<Warning>
Do not ignore the return values of `RUN_ALL_TESTS()`. Proper test integrators check and respect these codes to avoid masking failing tests.
</Warning>