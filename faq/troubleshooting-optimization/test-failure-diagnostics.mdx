---
title: "Tests are failing—how do I diagnose and fix the problem?"
description: "Guides users through interpreting failure messages, using logging and error reports, and debugging both test and production code. Includes examples of reading output, adjusting mock strictness, and isolating test causes."
---

# Diagnosing and Fixing Test Failures

When your tests fail, understanding and resolving the cause efficiently is critical to maintaining test suite stability and improving code quality. This guide walks you through interpreting failure messages, utilizing logging and error reports, adjusting mock strictness, and isolating test causes to quickly identify and address issues.

---

## 1. Interpreting Failure Messages

Failure messages are your primary diagnostic tool. They provide context about what assertion failed, where, and why.

- **Read the Message Carefully**: Look for details such as expected vs. actual values, argument match failures, or unmet expectations.

- **Check for Call Ordering Issues**: If you’re using sequences (`InSequence`), verify if calls happened out of order.

- **Watch for Uninteresting and Unexpected Calls**:
  - *Uninteresting calls* occur when a mock method is called without any explicit expectation; these generate warnings.
  - *Unexpected calls* happen when call arguments don’t match any existing expectation; these cause test failures.

- **Stack Traces**: Failure reports often include stack traces pinpointing where a failure originated.

```shell
[ RUN      ] FooTest.Bar
foo_test.cc:14: Failure
Expected equality of these values:
  bar
  3
  4
```

<Note>
If failure messages are unclear, consider increasing verbosity with `--gmock_verbose=info`.
</Note>

## 2. Using Logging and Verbosity Flags

GoogleMock provides verbosity levels to control the amount of diagnostic output during test runs:

- **Verbose Levels:**
  - `info`: Print all informational, warning, and error messages, including detailed stack traces.
  - `warning`: Print warnings and errors (default).
  - `error`: Show only error messages to reduce noise.

### How to Set Verbosity:

- Command-line flag:
  ```bash
  ./my_test --gmock_verbose=info
  ```

- Programmatically:
  ```cpp
  ::testing::FLAGS_gmock_verbose = "info";
  ```

### What You See at `info` Level:

- Detailed traces of all mock calls and matching expectations.
- Stack traces for uninteresting calls.
- Insight into default actions taken.

```shell
foo_test.cc:14: EXPECT_CALL(mock, F(_, _)) invoked
Stack trace: ...

foo_test.cc:14: Mock function call matches EXPECT_CALL(mock, F(_, _))...
    Function call: F("a", "good")
Stack trace: ...
```

<Warning>
Increasing verbosity can produce large outputs; use selectively when debugging.
</Warning>

## 3. Adjusting Mock Strictness

Mock strictness affects how uninteresting calls are handled:

- **NaggyMock (default)**: Warns on uninteresting calls.
- **NiceMock**: Suppresses warnings on uninteresting calls.
- **StrictMock**: Treats uninteresting calls as test failures.

### Changing Strictness:

```cpp
using ::testing::NiceMock;
using ::testing::StrictMock;

NiceMock<MockFoo> nice_foo;   // Ignores warnings for unexpected calls
StrictMock<MockFoo> strict_foo; // Fails on unexpected calls
```

### Use Cases:

- Use `NiceMock` in tests where warnings about uninteresting calls clutter output but are not critical.
- Use `StrictMock` when you want to enforce precise interaction protocols.

<Tip>
Prefer starting with `NiceMock` to reduce test brittleness; elevate to `StrictMock` only when necessary.
</Tip>

## 4. Isolating the Cause of Failures

When a test fails, isolating the failure's root cause accelerates fixes.

### Step-by-Step Isolation Techniques:

<Steps>
<Step title="Reproduce the Failure Consistently">
Ensure the failure occurs reliably to make diagnosis possible.
</Step>
<Step title="Run with Increased Verbosity">
Use `--gmock_verbose=info` to see mock call matching and invocation details.
</Step>
<Step title="Check Expectation Coverage">
Verify all expected calls are made and none are missing or exceeded.
</Step>
<Step title="Check Argument Matchers">
Inspect if argument matchers in `EXPECT_CALL` are correct and specific enough.
</Step>
<Step title="Use SCOPED_TRACE for Additional Context">
Add `SCOPED_TRACE` in test helper functions to pinpoint which call caused a failure.
</Step>
<Step title="Split Complex Tests">
Break down complex tests into smaller ones to localize failure.
</Step>
<Step title="Verify Setup and Teardown">
Check if test fixture setup or teardown corrupts state causing failures.
</Step>
</Steps>

### Example: Using SCOPED_TRACE

```cpp
void Helper(int n) {
  SCOPED_TRACE(absl::StrCat("Helper called with n=", n));
  EXPECT_EQ(Foo(n), 42);
}

TEST(MyTest, UsesHelper) {
  for (int i = 0; i < 3; i++) {
    Helper(i);
  }
}
```

If a failure occurs, the trace will indicate which `Helper` invocation failed.

## 5. Working with Error Messages and Debugging

- Use `EXPECT_FATAL_FAILURE` and `EXPECT_NONFATAL_FAILURE` to validate error handling code in tests.

- For debugging failures caused by mock misuse or assertion failures, examine the stack trace and error messages carefully.

- If assertions inside helper functions are not aborting the test as expected, consider using `ASSERT_NO_FATAL_FAILURE` wrappers or the `HasFatalFailure()` method to propagate failures.

- Use `Mock::VerifyAndClearExpectations(&mock_obj)` to force verification of mock expectations before test teardown to catch missed calls early.

## 6. Practical Tips and Best Practices

- **Prefer `ON_CALL` for default behavior** and `EXPECT_CALL` for actual call verification.

- Avoid over-specifying expectations; too many explicit expectations make tests brittle.

- Suppress warnings for methods not of interest using `NiceMock` or by explicit `EXPECT_CALL(...).Times(AnyNumber())`.

- Use `.RetiresOnSaturation()` on expectations that should become inactive after saturation to prevent overlapping matching.

- Keep mock methods and expectations readable by limiting matcher complexity.

- Use sequences (`InSequence`) with care to avoid overly brittle tests.

- Utilize `Debug` verbosity and call trace information when analyzing complex failures.

## 7. Troubleshooting Common Failure Scenarios

<AccordionGroup title="Common Failure Scenarios">
<Accordion title="Uninteresting Call Warnings">
Uninteresting calls happen when a mock method without an expectation is called.
- Solution:
  - Use `NiceMock` to suppress warnings.
  - Add a catch-all `EXPECT_CALL(mock, Method(_)).Times(AnyNumber())` if needed.
</Accordion>
<Accordion title="Unexpected Calls">
Unexpected calls happen when calls don't match any defined expectation.
- Causes:
  - Argument mismatch.
  - Missed setup of expected calls.
- Fix:
  - Adjust your `EXPECT_CALL`s or add missing ones.
  - Use `--gmock_verbose=info` to see call matching details.
</Accordion>
<Accordion title="Exceeded Call Count">
Calls made more times than specified in an expectation.
- Fix:
  - Increase the expected `Times()` count.
  - Use `.RetiresOnSaturation()` if saturation means no further matches.
</Accordion>
<Accordion title="Call Order Violations">
Using `InSequence` or `After` clauses can cause failures if calls occur out of order.
- Fix:
  - Check sequences and ordering constraints.
  - Reduce order restrictions if overly brittle.
</Accordion>
<Accordion title="Default Action Does Not Fit">
If a mock method returns non-default-constructible type without a specified action.
- Fix:
  - Specify default return values with `ON_CALL` or `DefaultValue<T>`.
  - Provide custom action using `.WillByDefault()` or `WillRepeatedly()`.
</Accordion>
</AccordionGroup>

## 8. Debugging Test and Production Code

GoogleMock's failure outputs and stack traces facilitate pinpointing the exact location and cause of errors.

- **Trace Mock Calls**: Enable call tracing with verbosity to see exactly which calls happened and which expectations they matched.

- **Verify Lifecycle**: Ensure mocks are destructed properly to trigger verification. Use `Mock::AllowLeak()` only if necessary.

- **Use Custom Print Functions**: Make sure your types have `PrintTo()` or `AbslStringify()` overloads to get readable failure messages.

- **Profiling and Logging**: Add extra logging in production or test code to isolate issues when failure messages are insufficient.

## 9. Example: Diagnosing an Unexpected Call

Given:

```cpp
EXPECT_CALL(mock, Foo(5));
...
mock.Foo(6);  // Test fails here
```

Run the test with increased verbosity:

```bash
./test_binary --gmock_verbose=info
```

You will see which `EXPECT_CALL` each call matches or fails to match. This helps identify that `Foo(6)` did not match any expectation because it expects `Foo(5)`.

---

# Further Reading & Related Topics

- [GoogleMock Cookbook](https://google.github.io/googletest/gmock_cook_book.html) — practical recipes for mocking patterns and workflows.
- [Mock Strictness Lifecycle](https://google.github.io/googletest/concepts/mock-behaviors-extensibility/mock-strictness-customization.html) — for controlling mock warnings and failures.
- [Matchers Reference](https://google.github.io/googletest/api/gmock_matchers.html) — detailed usage of argument matchers.
- [Assertions Reference](https://google.github.io/googletest/reference/assertions.html) — diagnostic assertion tools.
- [Test Lifecycle and Execution](https://google.github.io/googletest/concepts/core-architecture/test-lifecycle-execution.html) — understanding how tests run and report results.
- [Setup Troubleshooting FAQ](../faq/getting-started-faq/setup-troubleshooting) — for resolving integration and setup issues.

---

<Tip>
To streamline debugging, incorporate logging within your mock methods or use GoogleTest event listeners for enhanced test monitoring.
</Tip>

<Check>
Always verify that your mock object lifetimes and expectation setups align with your test execution flow to prevent elusive test failures.
</Check>

---