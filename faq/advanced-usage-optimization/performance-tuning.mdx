---
title: "How can I improve test performance and reliability?"
description: "Practical advice on optimizing test execution speed, minimizing flakiness, and handling large test suites. Includes tips for parallel execution, environment management, and other workflow optimizations."
---

# How can I improve test performance and reliability?

Optimizing your test suite to run efficiently and consistently is crucial for maintaining a productive development workflow, especially as your codebase and test suite grow. This page offers practical advice to speed up test execution, minimize flaky tests, and handle large or complex suites effectively through workflows, environment management, and best practices.

---

## 1. Speeding Up Test Execution

### a. Use Parallel Test Execution

Running tests in parallel is one of the most straightforward ways to reduce overall test runtime. GoogleTest supports parallelism through tools like `CTest`, Bazel, or custom test runners.

- **Divide your tests** into independent test executable binaries or test shards.
- **Leverage CTest's `--parallel` option** or build system capabilities to run multiple tests simultaneously.
- Ensure your tests are **independent and stateless** to avoid race conditions when run concurrently.

<Tip>
Parallel execution dramatically shortens feedback times, especially in CI environments. To avoid flaky tests, confirm tests do not share mutable global resources.
</Tip>

### b. Minimize Expensive Setup and Tear Down

Reduce the initialization costs within your tests:

- Use test fixtures (`TEST_F`) to share setup for groups of related tests.
- Cache or reuse expensive resources such as database connections or file handles where possible.
- Prefer **mocking** dependencies instead of real implementations that require costly operations.

### c. Avoid Over-Specifying Mock Expectations

Overly strict mock expectations cause unnecessary test failures and slowdowns.

- Use `ON_CALL` to specify default behaviors instead of excessive `EXPECT_CALL`s.
- Avoid specifying exact times (`Times(Exact(n))`) unless essential; prefer flexible cardinalities like `Times(AtLeast(n))` or `Times(AnyNumber())`.
- Suppress unnecessary warnings by choosing appropriate mock strictness modes (`NiceMock`, `NaggyMock`, or `StrictMock`).

### d. Use Efficient Matchers and Actions

Built-in matchers and actions are optimized; custom solutions should be efficient:

- Use wildcard matcher `_` when arguments are irrelevant to the test.
- Cache complex matchers in variables to avoid reconstruction.
- Use `ReturnPointee()` or lambdas for actions that depend on changing values instead of `Return()` with `std::ref()`.

## 2. Increasing Test Reliability and Reducing Flakiness

### a. Manage Test Environment Consistently

Flaky tests often stem from environment dependencies or timing issues.

- Isolate tests from external systems using mocks and fakes.
- Control shared resources to avoid tests interfering with each other.
- Fix test order dependencies by avoiding stateful or static shared data.

### b. Use Expectations and Sequences Appropriately

To reliably verify interaction behavior:

- Use `InSequence` or `Sequence` to enforce ordering when necessary.
- Apply `RetiresOnSaturation()` when expectations should deactivate after a number of calls.
- Avoid mixing expectations and calls in ways that cause undefined behavior (e.g., setting expectations after method use).

### c. Prefer `ON_CALL` for Default Behaviors

- Use `ON_CALL` to define how mocks behave by default without enforcing call counts or order.
- Reserve `EXPECT_CALL` to specifically verify actual method calls relevant to the test.
- This approach leads to less brittle tests and easier maintenance.

### d. Control Verbosity for Better Debugging

- Use the flag `--gmock_verbose=info` during test development to get detailed mock call traces.
- Switch to `--gmock_verbose=warning` or `error` for routine runs to avoid clutter.

## 3. Handling Large Test Suites

### a. Modularize Your Tests

Split your tests logically:

- Group related tests into multiple executables.
- Run subsets selectively during development.

### b. Use Test Sharding

- Distribute test execution across machines or cores using sharding to reduce wall-clock time.

### c. Continuous Integration (CI) Best Practices

- Automate parallel builds and test runs.
- Collect and aggregate test results properly using XML or other formats supported by GoogleTest and your CI.
- Use pre-submit runs on changed code areas to save time.

### d. Periodically Rerun Flaky Tests

- Introduce retry logic for flaky tests during CI or use specialized tools to identify flaky tests.

## 4. Practical Tips & Best Practices

<AccordionGroup title="Best Practices for Test Performance and Reliability">
<Accordion title="Use Mocking Wisely">
Mock objects reduce dependencies on expensive or unreliable components. Prefer mocks over real implementations for unit tests to ensure speed and stability.
</Accordion>
<Accordion title="Avoid Heavy Computations in Tests">
Keep tests lightweight. Move complex logic to production code, validate core logic in tests.
</Accordion>
<Accordion title="Keep Tests Independent">
Ensure tests do not rely on each other's execution order or shared state.
</Accordion>
<Accordion title="Regularly Profile Tests">
Use profiling and coverage tools to identify slow tests and optimize or refactor them.
</Accordion>
<Accordion title="Leverage GoogleTest and GoogleMock Flags">
Familiarize yourself with flags like `--gtest_filter`, `--gtest_shuffle`, `--gmock_verbose` to control test runs and diagnostics.
</Accordion>
<Accordion title="Maintain Clear Expectations">
Write clear and minimal mock expectations, avoiding overly rigid call counts or argument matchers.
</Accordion>
</AccordionGroup>

## 5. Troubleshooting Common Problems

### a. Tests Are Slow

- Check for expensive resource initialization in tests.
- Confirm mocks are used instead of real dependencies.
- Verify if tests run sequentially; enable parallel execution when safe.

### b. Tests Fail Intermittently (Flakiness)

- Look for race conditions or shared mutable state.
- Use `StrictMock` or `NaggyMock` carefully, as they may expose timing issues.
- Ensure tests clean up after themselves.

### c. Mock Expectations Not Met

- Confirm `EXPECT_CALL` is set before mock methods are called.
- Use `Mock::VerifyAndClearExpectations()` to enforce verification early.
- Use `--gmock_verbose=info` to trace mock call matching behavior.

## 6. Additional Resources

- [GoogleMock Best Practices Guide](https://google.github.io/googletest/gmock_best_practices.html) for deep strategies on writing maintainable mocks and expectations.
- [GoogleTest & GoogleMock CI Integration Guide](/guides/advanced-and-integration-guides/ci-integration-and-best-practices) to automate effective test execution in CI pipelines.
- [Setup and Installation](/guides/getting-started/setup-and-installation) for comprehensive build and environment configuration.

---

## Summary
This page guides you through practical techniques to improve test speed and reliability using GoogleTest and GoogleMock. It emphasizes parallel execution, efficient mock usage, managing flaky tests, and handling large test suites with best practices and troubleshooting tips to optimize your testing workflow.

---

## Example: Parallelizing Tests with `CTest`

```bash
# Run tests in 4 parallel jobs
ctest --parallel 4
```

## Example: Using NiceMock for Less Verbose Mocks

```cpp
using ::testing::NiceMock;
NiceMock<MockFoo> mock_foo;
ON_CALL(mock_foo, SomeMethod()).WillByDefault(Return(42));
EXPECT_CALL(mock_foo, ImportantMethod()).Times(1);
```

<Check>
Ensure all `EXPECT_CALL`s are set before exercising the mock objects for correct verification.
</Check>