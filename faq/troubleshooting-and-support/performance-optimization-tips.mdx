---
title: "Performance Optimization Tips"
description: "Advice for speeding up test suite execution, reducing test initialization overhead, managing resource-intensive mocks, and leveraging test runners or parallelization options. Helps improve developer productivity and feedback cycle speed."
---

# Performance Optimization Tips

This page offers practical guidance to accelerate your GoogleTest and GoogleMock test suites by reducing overheads in test initialization, managing resource-intensive mocks effectively, and leveraging parallelization strategies and test runner options.

Optimizing test execution will help decrease turnaround time, improve developer productivity, and enable faster feedback cycles.

---

## 1. Reducing Test Initialization Overhead

### Share Expensive Setup Using Per-Test-Suite Fixtures

GoogleTest by default creates fresh test fixtures for each test, which ensures independence but may incur high costs if setup is expensive.

To mitigate this, use per-test-suite setup and teardown:

```cpp
class ExpensiveTest : public ::testing::Test {
 protected:
  static void SetUpTestSuite() {
    // Initialize expensive shared resource
    shared_resource_ = new Resource();
  }

  static void TearDownTestSuite() {
    delete shared_resource_;
    shared_resource_ = nullptr;
  }

  // Accessible by tests
  static Resource* shared_resource_;
};

Resource* ExpensiveTest::shared_resource_ = nullptr;
```

This way, the costly setup runs only once per suite, significantly reducing overall runtime.


### Avoid Unnecessary Fixture Complexity

Keep test fixtures lean. Avoid unnecessary setup or mocks that aren’t used by all tests. Use separate fixtures or `TEST()` for simpler tests.


### Be Cautious with `ASSERT_*` in SetUp/TearDown

Using `ASSERT_*` in setup can abort early and cause resource leaks — prefer `EXPECT_*` or move critical checks to first test case.


## 2. Managing Resource-Intensive Mocks

### Use ON_CALL For Default Behavior

Define default behavior for mocks using `ON_CALL` rather than `EXPECT_CALL` to reduce the overhead of setting expectations on every test:

```cpp
ON_CALL(mock_object, Method(_))
    .WillByDefault(Return(default_value));
```

This makes tests faster and less brittle.


### Prefer NiceMock to Suppress Warnings on Uninteresting Calls

`NiceMock<T>` suppresses warnings for calls without explicit expectations, reducing noisy output and improving runtime.


### Delegate to Fakes Where Appropriate

If available, delegate mock behavior to a lightweight fake object with realistic behavior to avoid excessive setup in tests.


## 3. Leveraging Test Runner and Parallelization Options

### Run Tests in Parallel

Tests are often independent and can be parallelized to leverage multiple CPU cores.

Popular methods include:
- Using build system support (e.g., CTest, Bazel with sharding).
- Running multiple GoogleTest instances with `--gtest_filter` to split tests.
- Using `GTEST_TOTAL_SHARDS` and `GTEST_SHARD_INDEX` environment variables for sharding across machines.


### Use Test Filtering and Sharding

Filter your test runs to focus on relevant subsets to reduce runtime during development:

```bash
./my_test --gtest_filter=MyTestSuite.*
```

Use sharding environment variables to distribute test workloads across machines:

```bash
export GTEST_TOTAL_SHARDS=4
export GTEST_SHARD_INDEX=0
./my_test
```

Repeat on other machines with `GTEST_SHARD_INDEX` set to 1, 2, and 3.


### Use Test Repeat and Shuffle to Detect Flaky Tests

Run tests repeatedly with `--gtest_repeat` and shuffle their execution order to detect flaky and order-dependent tests early.

### Build and Link with Optimization

Ensure your test binary is compiled and linked with optimization flags (e.g., `-O2` or above) for faster execution.


## 4. Practical Tips and Best Practices

- Prefer `EXPECT_*` over `ASSERT_*` to allow multiple failures per run, improving debugging efficiency.
- Use `INSTANTIATE_TEST_SUITE_P` and parameterized tests to avoid duplicative test code, providing concise coverage.
- Keep tests _independent_ to safely run in parallel and to minimize debugging complexity.
- Regularly profile test execution to identify bottlenecks.
- Consider experimental features for faster initialization and execution available in future GoogleTest releases.


## 5. Troubleshooting Performance Issues

### Common Symptoms

- Slow test runs due to heavy fixture setup.
- Time wasted on mocking unnecessary methods or setting redundant expectations.
- Tests running sequentially despite multi-core availability.
- Excessive memory usage caused by large shared resources.

### Diagnostic Steps

- Use verbose logging with `--gtest_brief=0 --gtest_print_time=1` to analyze which tests dominate runtime.
- Check your mock usage to ensure minimal expectations and avoid overspecification.
- Profile CPU/memory during runs to locate expensive operations.
- Inspect usage of global/static resources in fixtures.

### Remedies

- Refactor tests to share resources only at test suite or global environment level if possible.
- Convert overly specific `EXPECT_CALL`s to `ON_CALL`s or `NiceMock`.
- Enable test sharding or parallel execution.
- Remove or optimize expensive setup not strictly required for test correctness.


---

## Related Documentation and Resources

- [GoogleTest Primer](../primer.md) - for foundational test writing
- [Optimizing Test Performance Guide](../guides/real-world-examples-and-integration/optimizing-test-performance.mdx) - in-depth strategies
- [Configuring Your Project](../getting-started/setup-and-installation/configuring-your-project.mdx) - to set up builds efficiently
- [Running and Interpreting Test Results](../getting-started/first-test-and-validation/running-and-interpreting-test-results.mdx) - to analyze test runs

---

Implementing these strategies will markedly improve test suite speed and reliability, making your development process more efficient and enjoyable.

For further assistance, see Troubleshooting guide or reach out to community forums and support channels.
