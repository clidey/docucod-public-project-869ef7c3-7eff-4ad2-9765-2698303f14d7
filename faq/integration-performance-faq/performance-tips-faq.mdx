---
title: "Performance Optimization"
description: "Provides strategies for running large or slow test suites efficiently, including test parallelization, filtering, and best practices for speeding up builds and execution."
---

# Performance Optimization

Efficient test execution is key to maintaining a fast, reliable development cycle when working with large or slow test suites. This guide provides practical strategies to help you speed up test builds and reduce execution time, enabling smooth integration into continuous integration pipelines and local development workflows.

---

## 1. Speeding Up Test Execution

### Parallelizing Tests

Most test runners, including those used with GoogleTest and GoogleMock, allow parallel execution of tests. Running tests concurrently maximizes CPU utilization and drastically shortens the wall-clock time needed to complete large test suites.

**How to parallelize your tests:**

- Use your build system or test runner's parallel execution features (e.g., `ctest -jN` for CTest, or Bazel's parallelism).
- Divide your tests into shards (groups) to run separately in CI or local setups.
- Avoid shared global state or modify tests to isolate state where necessary.

**Example:**

```bash
# Using gtest_parallel tool to run tests across multiple processes
gtest_parallel ./my_test_binary
```

**Benefits:**

- Linear cut-down of total test time proportional to the number of CPU cores.
- Can be combined with sharding to run across multiple machines.

### Test Filtering

Running all tests every time can be expensive and slow. Use filtering mechanisms to run only subsets of tests relevant to your changes.

- Use the `--gtest_filter` flag to specify which tests to run by name or pattern.
- Use tags or test suite grouping to organize tests by feature or speed.
- Run fast unit tests more frequently, and heavy integration/death tests less often.

**Example:**

```bash
# Run tests with names starting with 'Foo' but excluding 'Slow'
./my_test_binary --gtest_filter=Foo*:-*Slow*
```

### Avoid Excessive Test Fixture Setup

Complex fixture setup can slow tests down significantly.

- Initialize only whatâ€™s necessary per test.
- Reuse fixtures for multiple tests where possible.
- Cache expensive setup results if test data does not change.

### Minimize Mock Complexity

Mocks should reflect real interactions without unnecessary overhead.

- Avoid overly complex mock behaviors that slow test execution.
- Use simple expectations when possible.
- Consider using NiceMock or NaggyMock to reduce verbose warnings that slow tests.

### Continuous Integration (CI) Optimization

Design your CI pipelines to run tests efficiently:

- Run quick tests on push, and slower tests nightly or on demand.
- Break integration tests into smaller suites that can run in parallel.
- Cache build artifacts efficiently to avoid redundant compilation.

---

## 2. Best Practices for Large Test Suites

### Test Sharding

Sharding splits tests into smaller chunks that can run independently.

- Assign tests to shards based on test name, file path, or other metadata.
- Configure CI jobs to run each shard on a separate machine or container.
- Aggregate test results after all shards finish.

**Benefits:**

- Linear scale-out on multiple machines.
- Enables testing of very large suites in practical time frames.

### Balancing Test Suite Coverage and Speed

- Identify and tag slow tests for selective execution.
- Mark flaky tests distinctly and isolate their execution.
- Optimize or rewrite slow tests where possible.

### Build Optimization

- Precompile headers commonly used throughout your test code.
- Limit recompilation by precise dependency management.
- Offload test binaries onto SSDs or faster storage media.

### Using `Mock::VerifyAndClearExpectations`

Frequently verify and clear mock expectations to avoid surprises at destruction time which could delay test completion or cause flaky results:

```cpp
Mock::VerifyAndClearExpectations(&mock_object);
```

Clear expectations as soon as tests complete their relevant logic to facilitate deterministic test behavior.

### Use `NiceMock` to Suppress Unnecessary Warnings

Uninteresting mock calls generate warnings by default and add noise to test outputs, possibly slowing test runs.

- Wrap mocks with `NiceMock` if you do not care about warnings on uninteresting calls.

```cpp
using ::testing::NiceMock;
NiceMock<MockFoo> nice_mock;
```

---

## 3. Troubleshooting Performance Issues

<AccordionGroup title="Common Performance Issues">
<Accordion title="Slow Test Setup or Teardown">
Fixtures with expensive setup or teardown can dominate runtimes.

**Solution:** Profile fixture setup times and optimize or cache as needed.
</Accordion>
<Accordion title="Tests Interfering with Each Other">
Shared state or resources can force tests to run sequentially or cause flakiness.

**Solution:** Refactor tests for isolation and independence.
</Accordion>
<Accordion title="Excessive Mock Complexity">
Highly complex mocks with many actions or matchers can slow execution.

**Solution:** Simplify mocks, reduce chained expectations, and avoid unnecessary side effects.
</Accordion>
<Accordion title="Suboptimal Build Configuration">
Repeated builds or linking large binaries can slow overall iteration.

**Solution:** Use incremental builds, isolate test code, leverage build caching.
</Accordion>
</AccordionGroup>

---

## 4. Summary & Recommendations

- Leverage parallel test execution and test sharding aggressively.
- Use test filters to run only what is necessary during iterative development.
- Favor simple mocks and lean test fixtures.
- Use `NiceMock` to reduce noise and speed tests when strictness is not needed.
- Profile and optimize slow tests and setups regularly.
- Apply CI best practices to scale test coverage without compromising feedback time.

---

## Related Documentation

- [Guides/Optimizing Test Performance and Scaling](/guides/real-world-integration/performance-scaling)
- [GoogleMock Cookbook](https://google.github.io/googletest/gmock_cook_book.html) (for writing efficient mocks)
- [Managing Test Dependencies and Configuration](/guides/getting-started/managing-test-dependencies)
- [Build System Integration](/guides/real-world-integration/build-system-integration)
- [Troubleshooting and FAQ](/guides/real-world-integration/troubleshooting-faq)

---

For detailed techniques on writing effective mock expectations and managing call counts for performance considerations, refer to the [Cardinalities and Strictness Guide](/guides/mocking-advanced/cardinalities-strictness).

<Check>
Optimizing performance requires careful balancing of test coverage, reliability, and speed. Use the above strategies iteratively for continuous improvement.
</Check>
