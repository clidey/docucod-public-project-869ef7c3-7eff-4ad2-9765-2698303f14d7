---
title: "Running and Interpreting Test Results"
description: "Instructions for running GoogleTest test binaries, interpreting output, and understanding test results. Covers different runner options, command-line flags, and troubleshooting common test execution issues."
---

# Running and Interpreting Test Results

## 1. Overview
This guide walks you through how to run your GoogleTest test binaries, read the output they produce, and interpret the results. It explains different ways to invoke tests, common command-line flags that modify test execution behavior, and what the test output messages mean. It also provides troubleshooting advice for common issues when running tests.

---

## 2. Prerequisites
- You have built your test binary with GoogleTest or GoogleMock linked.
- Your test code defines tests using `TEST()`, `TEST_F()`, or other GoogleTest macros.
- Familiarity with basics of GoogleTest, including writing tests and assertions.

---

## 3. Expected Outcomes
- Successfully execute all registered tests in your binary.
- Receive clear and structured output showing which tests passed, failed, or were skipped.
- Understand the cause for any test failures or errors.

---

## 4. Time Estimate
Running the tests and reading their basic output takes seconds to minutes, depending on the size of your test suite.

---

## 5. Difficulty Level
Beginner to Intermediate

---

## 6. Running Tests: Step-by-Step

<Steps>
<Step title="Run the Test Binary">
  Execute your compiled test executable from the command line. For example:

  ```bash
  ./my_test_binary
  ```

  After running, the binary automatically runs all registered tests and prints the results.

  **Expected result:** You see a console output summarizing the tests run, their pass/fail status, and overall result.
</Step>

<Step title="Observe the Test Output">
  The output lists:

  - Test cases and individual tests run
  - Pass or fail indication for each
  - Additional messages such as failures, errors, or skipped tests

  It ends with a summary line similar to:

  ```
  [==========] 5 tests from 2 test suites ran. (123 ms total)
  [  PASSED  ] 5 tests.
  ```

  **Expected result:** All your tests pass unless something failed or was disabled.
</Step>

<Step title="Use Command-Line Flags to Control Test Execution">
  GoogleTest provides helpful command-line options:

  - `--gtest_filter=`: Run only tests matching a pattern.
  - `--gtest_repeat=`: Run tests multiple times.
  - `--gtest_break_on_failure`: Break into debugger on failure.
  - `--gtest_output=`: Output results in XML or JSON formats.

  Example to run only tests starting with `MyTest.`:

  ```bash
  ./my_test_binary --gtest_filter=MyTest.*
  ```

  **Expected result:** Only selected tests run and their results appear.
</Step>

<Step title="Check Exit Code of the Test Binary">
  Your test executable returns `0` if all tests pass and `1` if any test fails.

  Use this in scripts or CI pipelines to detect test failures automatically.

  **Example in Bash:**

  ```bash
  ./my_test_binary
  if [ $? -ne 0 ]; then
    echo "Tests failed."
  fi
  ```

  **Expected result:** Proper exit code corresponding to test success.
</Step>
</Steps>

---

## 7. Understanding Test Output Messages

GoogleTest categorizes test outcomes with clear messages:

| Result Type           | Description                                                  | Notes                                      |
|----------------------|--------------------------------------------------------------|--------------------------------------------|
| **Passed**           | Test assertions all succeeded.                               | Shown with `[  PASSED  ]` in the output.   |
| **Failure**          | An `ASSERT_*` or `EXPECT_*` macro failed.                    | Details include file, line, and message.   |
| **Fatal Failure**    | A fatal failure aborts current test execution immediately.   | Denoted by `ASSERT_*` that fails.          |
| **Non-fatal Failure**| A failed test assertion does not abort the test.             | Denoted by `EXPECT_*` that fails.          |
| **Skipped**          | Tests disabled or filtered out.                              | Shown as `[  SKIPPED  ]`.                   |
| **Death Test**       | Special tests expecting abnormal program termination.        | Failures indicated in their own section.  |

<Tip>
Pay close attention to the output line referencing the failed test’s source line. It provides exact location and error detail to help fix issues quickly.
</Tip>

---

## 8. Common Flags for Running Tests

- `--gtest_filter=PATTERN`
  - Run only tests matching this pattern.
  - Supports wildcards `*` and negative filters.

- `--gtest_repeat=N`
  - Runs the entire test suite `N` times; useful for detecting flaky tests.

- `--gtest_shuffle`
  - Runs tests in random order to identify order dependencies.

- `--gtest_break_on_failure`
  - Breaks into the debugger on the first failed assertion.

- `--gtest_catch_exceptions=BOOL`
  - Enables or disables catching exceptions.

- `--gtest_output=xml:[PATH]`
  - Exports test results to XML file at given path.

<Note>
You can combine multiple flags to fine-tune test runs, e.g., run a specific test repeatedly and output results.
</Note>

---

## 9. Troubleshooting Common Issues

<AccordionGroup title="Test Execution Issues">
<Accordion title="No Tests Run or Tests Ignored">
Ensure your test binary actually contains tests. Check if you accidentally filtered out all tests or disabled tests via naming (e.g., prefixing with `DISABLED_`).

Confirm that you have linked your test code with GoogleTest and/or GoogleMock properly.
</Accordion>

<Accordion title="Tests Fail Immediately or Crash on Startup">
Check initialization, including calls to `testing::InitGoogleTest(&argc, argv);` before running `RUN_ALL_TESTS()`.

Validate that your tests and fixtures do not throw exceptions that are not caught if exception catching is enabled.
</Accordion>

<Accordion title="Unexpected Outputs or Mismatched Expectations">
If mock expectations are not met, GoogleMock outputs informative messages about which calls were expected, unexpected, or excessive.

Review the details in the output to adjust your `EXPECT_CALL` or `ON_CALL` usage.
</Accordion>

<Accordion title="Exit Code Always Zero No Matter What">
Make sure your main function returns the result of `RUN_ALL_TESTS()`.

Returning a fixed value without the test result causes false positives.
</Accordion>
</AccordionGroup>

---

## 10. Best Practices & Tips

- Use `--gtest_filter` to run only relevant tests during development for faster feedback.
- Combine `--gtest_shuffle` with `--gtest_repeat` to detect flaky tests.
- Always check the exit code from your test binary programmatically in CI systems.
- Capture output in XML format with `--gtest_output` for integration with test reporting tools.
- For embedded platforms like ESP32 or Arduino, GoogleTest adapts to the platform’s main loop style; consult platform-specific docs.
- Prefer `EXPECT_*` macros to allow multiple failures to surface in one run, except when continuing after failure makes no sense.

---

## 11. Advanced Usage

If you need to customize test execution further, consider:

- Writing a custom `main` function that initializes GoogleTest/GoogleMock and sets up the environment.
- Using GoogleMock’s facilities to track mock call counts and behavior within tests.
- Using death tests for verifying expected program termination.

Refer to other guides for custom main program creation and mock-specific test flows.

---

## 12. Next Steps & Related Content

- [Writing Your First Test](/getting-started/first-test-usage-validation/creating-first-test): Learn to write your initial tests.
- [Building & Running Tests](/getting-started/first-test-usage-validation/building-running-tests): Understand build system integration and execution.
- [Troubleshooting and Validation](/getting-started/first-test-usage-validation/troubleshooting-validation): Common problems and how to resolve them.
- [Using GoogleMock](/guides/advanced-testing-patterns/using-gmock): Learn to add mocks and expectations to tests.
- [Mocking Reference](/api-reference/core-mocking-apis/expectations-on-call): Reference for mock macros and behaviors.

---

## 13. Example: Running Tests and Filtering

```bash
# Run all tests
./my_test_binary

# Run only tests in MathTest suite
./my_test_binary --gtest_filter=MathTest.*

# Run specific test MyTest.UseFeature
./my_test_binary --gtest_filter=MyTest.UseFeature

# Run the test suite 10 times
./my_test_binary --gtest_repeat=10

# Produce XML report
./my_test_binary --gtest_output=xml:report.xml
```

---

## 14. Troubleshooting Sample Output

### Example Failure Output

```
[ RUN      ] FactorialTest.HandlesZeroInput
googlemock/test/factorial_test.cc:10: Failure
Expected equality of these values:
  Factorial(0)
    Which is: 0
  1
[  FAILED  ] FactorialTest.HandlesZeroInput (0 ms)
```

- The file and line number point exactly to the failed assertion.
- The failure message shows actual vs expected.

### Mismatch in Mock Expectations

```
Expected mock call: Foo(5)
Actual call: Foo(4)
This is unexpected.
```
Check your `EXPECT_CALL` for argument correctness.

---

## 15. Platform Considerations

On embedded platforms (ESP8266, ESP32, Arduino), the entry point is often a pair of `setup()` and `loop()` functions rather than `main()`:

```cpp
void setup() {
  testing::InitGoogleMock();
}
void loop() {
  RUN_ALL_TESTS();
}
```

Your tests run within the continuous loop naturally fitting the platform constraints.

This specialized setup alleviates manual invocation.

---

## Resources and References
- [GoogleTest Primer - Invoking Tests and Using main()](https://google.github.io/googletest/primer.html#invoking-the-tests)
- [GoogleMock README](https://github.com/google/googletest/blob/main/googlemock/README.md)
- [Mocking Reference for Expectations](https://google.github.io/googletest/reference/mocking.html#EXPECT_CALL)
- [Command Line Flags](https://google.github.io/googletest/reference/flags.html)

---

## Summary
Running and interpreting test results effectively ensures reliable feedback during development and integration. By mastering test invocation commands and output interpretation, you can quickly identify problems and verify code correctness.