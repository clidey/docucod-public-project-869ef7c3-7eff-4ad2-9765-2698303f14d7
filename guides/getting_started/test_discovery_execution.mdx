---
title: "Test Discovery and Execution Patterns"
description: "Master the mechanics of automatic test discovery and explore common approaches for running individual or grouped tests. Learn about test registration, test runners, and how failures are reported."
---

# Test Discovery and Execution Patterns

Master the mechanics of automatic test discovery and explore common approaches for running individual or grouped tests. Learn about test registration, test runners, and how failures are reported.

---

## Overview

GoogleTest is designed to automatically detect and run tests defined in your codebase, providing a seamless experience for developing, organizing, and executing C++ tests. This page focuses specifically on the patterns and mechanisms behind test discovery and execution, empowering you to: 

- Understand how tests are registered and discovered
- Run all or selected tests efficiently
- Group related tests into suites
- Control test ordering, filtering, and execution behavior
- Respond effectively to test failures

## Prerequisites

Before proceeding, ensure that:

- You have a C++ project that includes GoogleTest and that you have included `<gtest/gtest.h>` in your source files.
- Test functions or fixtures are written using GoogleTest macros such as `TEST()`, `TEST_F()`, `TEST_P()`, or registered dynamically via `RegisterTest()`.
- Your build system is properly configured to link against GoogleTest libraries and properly calls `InitGoogleTest()` and `RUN_ALL_TESTS()`.

## Expected Outcome

By following this guide, you will:

- Grasp how GoogleTest identifies tests automatically
- Know how to write and register tests that GoogleTest can discover
- Understand test runners and main function requirements
- Learn filtering, sharding, and execution order control techniques
- Gain insight into event listeners for custom test execution and reporting

## Time Estimate

15-30 minutes to read and experiment

## Difficulty Level

Intermediate (some C++ and test framework familiarity expected)

---

## 1. Test Registration and Discovery

### Automatic Registration Through Macros

GoogleTest uses C++ macros (`TEST()`, `TEST_F()`, `TEST_P()`) to define tests. Each test macro registers the test automatically at compile/link time. There is **no need for manual enumeration** of tests.

Example:

```cpp
TEST(FactorialTest, HandlesZeroInput) {
  EXPECT_EQ(Factorial(0), 1);
}
```

This creates a test called `FactorialTest.HandlesZeroInput` that GoogleTest discovers and runs.

### Dynamic Registration

When macros don't suit your needs (for example, when test parameters are determined at runtime), you can register tests dynamically via `testing::RegisterTest()`:

```cpp
testing::RegisterTest(
    "MySuite", "DynamicTest", nullptr, nullptr, __FILE__, __LINE__, []() {
      return new MyTestFixture();
    });
```

Every registered test must return a pointer to a fixture inheriting from `testing::Test`.

### Test Suites and Naming

Tests are grouped into *test suites* (previously called *test cases*). The first argument to `TEST()` is the test suite name, and the second is the individual test name.

Naming conventions:

- Suites and test names must be valid C++ identifiers and shouldn't contain underscores (`_`).
- Suites can contain multiple related tests.

This organization makes it easier to run subsets of tests by suite.

---

## 2. Test Execution Patterns

### Writing `main()` and Running Tests

Most test executables simply perform the following:

```cpp
int main(int argc, char** argv) {
  ::testing::InitGoogleTest(&argc, argv);
  return RUN_ALL_TESTS();
}
```

- `InitGoogleTest()` initializes the framework and parses command-line flags.
- `RUN_ALL_TESTS()` discovers and runs all tests registered.

**Important:** Return the value of `RUN_ALL_TESTS()` from `main()` as it reports success/failure.

### Using Provided `gtest_main` Library

GoogleTest provides a prebuilt `gtest_main` library which contains a default `main()` implementation with the above pattern. Link to it if you don't need custom `main()` behavior.

### Selective Test Running with Filters

Run a subset of tests by specifying the `--gtest_filter` flag:

```sh
./my_test --gtest_filter=MySuite.*
```

The filter is a colon-separated list of positive patterns optionally followed by `-` and negative patterns (wildcards like `*` and `?` supported).

Examples:

- `--gtest_filter=FooTest.*` — run all tests in `FooTest` suite
- `--gtest_filter=*.HandlesZeroInput` — run all tests named `HandlesZeroInput`
- `--gtest_filter=MySuite.*-MySuite.BadTest` — run all except `MySuite.BadTest`

### Stopping on First Failure

Use flag `--gtest_fail_fast` or environment variable `GTEST_FAIL_FAST=1` to stop test execution upon the first failure.

### Repeating Tests

Repeat the entire test run multiple times with `--gtest_repeat=N`. A negative number repeats forever. Useful for catching flaky tests.

### Shuffling Test Order

Execute tests in random order by setting `--gtest_shuffle`. This helps discover test dependencies.

---

## 3. Using Test Fixtures

### Setup and Teardown Patterns

Test fixtures (`TEST_F()`) allow sharing common setup/teardown code per test suite.

For example:

```cpp
class QueueTest : public testing::Test {
 protected:
  void SetUp() override {
    // Called before each test
  }

  void TearDown() override {
    // Called after each test
  }

  Queue<int> queue_;
};
```

Each test defined with `TEST_F(QueueTest, TestName)` runs with a fresh fixture to ensure isolation.

### Per-Test-Suite Setup

For expensive shared resources, define `static void SetUpTestSuite()` and `static void TearDownTestSuite()` methods. These run once per suite before the first test and after the last test respectively.

---

## 4. Event Listeners and Customizing Test Runs

### Event Listener API

GoogleTest provides `TestEventListener` interface for capturing detailed testing events such as test start, finish, failures, environment setup/teardown, and program start/end.

Subclassing `testing::EmptyTestEventListener` allows overridable hooks for:

- `OnTestProgramStart`, `OnTestProgramEnd`
- `OnTestSuiteStart`, `OnTestSuiteEnd`
- `OnTestStart`, `OnTestEnd`
- `OnTestPartResult` — called after every assertion
- `OnEnvironmentsSetUpStart`, `OnEnvironmentsTearDownStart` etc.

### Adding Custom Listeners

Append your listener to the list in `main()` before running tests:

```cpp
int main(int argc, char** argv) {
  ::testing::InitGoogleTest(&argc, argv);
  auto& listeners = ::testing::UnitTest::GetInstance()->listeners();

  // Removes default console output
  delete listeners.Release(listeners.default_result_printer());

  listeners.Append(new MyCustomListener());

  return RUN_ALL_TESTS();
}
```

### Ordering of Events

- `On*Start` events are sent to listeners in the order added.
- `On*End` events are sent in reverse order.

This allows later listeners to wrap output of earlier ones.

---

## 5. Reporting Test Results and Failure Handling

### Assertions Determine Test Outcomes

Tests use assertions like `EXPECT_*` (non-fatal) and `ASSERT_*` (fatal) to verify correctness. A single fatal failure aborts the current test, while non-fatal failures allow it to continue.

### Failure Details

GoogleTest reports file names, line numbers, and failure messages on assertion failures.

You can stream custom messages into assertions for better context:

```cpp
EXPECT_EQ(x.size(), y.size()) << "Vectors differ in length!";
```

### Test Properties

Log additional information via `RecordProperty("key", value)` inside tests or fixtures to be included in XML or JSON output reports.

### XML/JSON Output

Enable detailed XML or JSON test reports using the `--gtest_output` flag, e.g., `--gtest_output=xml:report.xml`.

### Handling Premature Test Termination

GoogleTest supports detection of premature test program exits using environment variables (e.g., `TEST_PREMATURE_EXIT_FILE`), which helps CI systems detect crashed tests.

### Exception Behavior

By default, GoogleTest catches exceptions thrown in tests and marks tests as failed. This can be disabled for debugging purposes with the `--gtest_catch_exceptions=0` flag.

---

## 6. Test Execution Lifecycle

The core lifecycle involves the following steps:

1. GoogleTest initializes and parses the command line flags with `InitGoogleTest()`.
2. Test fixtures and tests are registered automatically.
3. `RUN_ALL_TESTS()` is called:
   - Global test environments are set up.
   - Tests and test suites run in the defined or shuffled order.
   - Test suite fixtures: `SetUpTestSuite()` and `TearDownTestSuite()` run appropriately.
   - Individual tests are executed with per-test fixture setup and teardown.
   - Failures are recorded and reported.
   - Global test environments are torn down.
4. Results are printed to console and optionally saved (XML/JSON).

---

## 7. Troubleshooting Common Issues

- **No tests run:** Make sure tests are registered correctly with macros or `RegisterTest()`. Verify correct linking.
- **Tests not discovered:** Check naming conventions and ensure that `RUN_ALL_TESTS()` is called after `InitGoogleTest()`.
- **Tests behave unexpectedly when run multiple times:** Use proper fixture `SetUp()` and `TearDown()` methods to isolate state.
- **Failures not reported with detailed info:** Use assertions properly with custom messages.
- **Conflicts between `TEST()` and `TEST_F()` in same test suite:** Avoid mixing test fixture types in one suite; each suite must use a consistent fixture.
- **Output cluttered with default printer and custom listeners:** Remove default printer before adding custom listeners.

---

## Code Example: Basic GoogleTest Program

```cpp
#include <gtest/gtest.h>

int Factorial(int n) {
  return (n <= 1) ? 1 : n * Factorial(n - 1);
}

// Simple test case
TEST(FactorialTest, HandlesZeroInput) {
  EXPECT_EQ(Factorial(0), 1);
}

// Test fixture example
class StackTest : public ::testing::Test {
 protected:
  void SetUp() override {
    stack_.push(1);
  }

  std::stack<int> stack_;
};

TEST_F(StackTest, IsNotEmptyAfterPush) {
  EXPECT_FALSE(stack_.empty());
}

int main(int argc, char** argv) {
  ::testing::InitGoogleTest(&argc, argv);
  return RUN_ALL_TESTS();
}
```

---

## Diagram: Test Discovery and Execution Flow

```mermaid
flowchart TD
  A[Start Test Program] --> B[InitGoogleTest(argc, argv)]
  B --> C[Test Registration (via TEST()/TEST_F()/RegisterTest)]
  C --> D[RUN_ALL_TESTS() Called]
  D --> E[SetUp Global Environments]
  E --> F{Any Tests To Run?}
  F -->|No| G[Skip Test Execution]
  F -->|Yes| H[Prepare Test Suites and Fixtures]
  H --> I[Run Each Test Suite]
  I --> J[Run Each Test in Suite]
  J --> K[SetUp Test Fixture]
  K --> L[Execute Test Body]
  L --> M[TearDown Test Fixture]
  M --> N{More Tests?}
  N -->|Yes| J
  N -->|No| O[Run TearDownTestSuite()]
  O --> P{More Test Suites?}
  P -->|Yes| I
  P -->|No| Q[TearDown Global Environments]
  Q --> R[Report Results]
  R --> S[End Test Program]
```

---

## Additional Tips & Best Practices

- Prefer `EXPECT_*` over `ASSERT_*` unless failure should abort test immediately.
- Use test fixtures to share setup/teardown logic within a suite.
- Avoid coupling tests; each test should be independent and repeatable.
- Use filtering and sharding pragmatically for large test suites.
- Record properties for additional metadata useful in reports.
- Use event listeners for custom logging or integrating with other tools.

## Related Documentation

- [GoogleTest Primer](primer.md) – Basics of writing tests and assertions.
- [Test Macros and Assertions](reference/testing.md#TEST) – Reference for test writing macros.
- [Event Listeners](reference/testing.md#TestEventListener) – For customizing test output.
- [Parameterization: Value- and Type-Parameterized Tests](guides/advanced_testing_patterns/parameterized_tests.md) – For data-driven testing.

## Next Steps

- Experiment writing small tests using `TEST()` and `TEST_F()`.
- Explore filtering and command-line options to run subsets of tests.
- Implement custom event listeners to capture fine-grained test execution data.
- Learn about advanced assertions and parameterization for scalable tests.

---