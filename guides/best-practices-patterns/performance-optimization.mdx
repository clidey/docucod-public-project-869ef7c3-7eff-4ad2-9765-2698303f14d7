---
title: "Improving Test Performance"
description: "Tips and strategies for optimizing the speed and efficiency of your test suite. Discusses parallel test execution, fixture reuse, and minimizing unnecessary test work for large-scale projects."
---

# Improving Test Performance

## Workflow Overview

### Task Description
This guide helps you optimize the speed and efficiency of your GoogleTest test suites. It focuses on actionable strategies such as running tests in parallel, reusing fixtures, and minimizing unnecessary work during test runs, especially beneficial in large-scale projects.

### Prerequisites
- You should have a working GoogleTest setup with existing tests.
- Basic familiarity with test fixtures, `TEST` and `TEST_F` macros is assumed.
- Understanding of test execution and resource management concepts.

### Expected Outcome
By following this guide, you will reduce test execution times, better leverage system resources, and improve test suite maintenance and scalability.

### Time Estimate
15-30 minutes to implement and experiment with these techniques.

### Difficulty Level
Intermediate - assumes working knowledge of GoogleTest and C++ testing workflows.

---

## Step-by-Step Instructions

### 1. Enable Parallel Test Execution

GoogleTest offers methods to run tests concurrently, reducing overall runtime.

- **Use test sharding to split tests across multiple workers:**

  1. Set environment variables:

     - `GTEST_TOTAL_SHARDS`: Total number of parallel test shards/machines.
     - `GTEST_SHARD_INDEX`: Index of the current shard (zero-based).

  2. Run the same test executable on each shard/machine with these environment variables set differently.

- **Result:** Each shard runs a subset of tests ensuring no overlap and faster aggregate execution.

- **Verification:** Check that test logs only show expected shards running their test subsets.

- **Note:** This is orchestrated outside GoogleTest, such as in CI pipelines or custom runners.

### 2. Reuse Test Fixtures and Shared Resources

Test fixtures help prepare common data or environment. Proper reuse minimizes redundant setup.

- **Implement per-test-suite setup/teardown:**

  1. In your fixture, declare shared static members for costly resources.
  2. Define `static void SetUpTestSuite()` to initialize the shared resource once before all suite tests.
  3. Define `static void TearDownTestSuite()` to clean up after all tests.

- **Example:**

  ```c++
  class FooTest : public testing::Test {
  protected:
    static void SetUpTestSuite() {
      shared_resource_ = new ExpensiveObject();
    }

    static void TearDownTestSuite() {
      delete shared_resource_;
      shared_resource_ = nullptr;
    }

    static ExpensiveObject* shared_resource_;
  };

  ExpensiveObject* FooTest::shared_resource_ = nullptr;
  ```

- **Benefits:**

  - Avoids repeated expensive setup for each test.
  - Tests remain independent but benefit from shared state.

- **Verification:** Confirm initialization logs or breakpoints fire only once per suite.

### 3. Minimize Unnecessary Test Work

Reduce redundant computation and excessive test invocation.

- **Avoid redundant fixture setup:** If common setup is required for subsets of tests only, consider subclassing fixtures or using composition.

- **Disable slow or unnecessary tests temporarily:** Use the `DISABLED_` prefix on test or test suite names to exclude them without deleting code.

- **Use value-parameterized or typed tests:** Reduce code duplication by combining similar tests into parameterized forms, lowering compile time and improving manageability.

- **Limit heavy resource usage:** For instance, limit database or network access in tests by mocking or using lightweight alternatives.

- **Verification:** Monitor test duration logs and ensure only intended tests run.

### 4. Practical Tips for Large-Scale Test Suites

- Keep tests small and focused to reduce setup times.
- Avoid global state between tests to ensure independence.
- Use `--gtest_shuffle` flag to detect inter-test dependencies.
- Run repeated tests (`--gtest_repeat`) under shuffle for flakiness detection.
- Make use of GoogleTestâ€™s XML or JSON output for performance profiling.

---

## Examples & Code Samples

### Parallel Test Execution Sample

Using **sharding environment variables** in Linux shell:

```sh
export GTEST_TOTAL_SHARDS=4
export GTEST_SHARD_INDEX=0
./my_tests &
export GTEST_SHARD_INDEX=1
./my_tests &
export GTEST_SHARD_INDEX=2
./my_tests &
export GTEST_SHARD_INDEX=3
./my_tests
wait
```

### Fixture Reuse Sample

```c++
class DatabaseTest : public ::testing::Test {
 protected:
  static DatabaseConnection* db_;

  static void SetUpTestSuite() {
    db_ = new DatabaseConnection("test_db");
    db_->Connect();
  }

  static void TearDownTestSuite() {
    db_->Disconnect();
    delete db_;
    db_ = nullptr;
  }
};

DatabaseConnection* DatabaseTest::db_ = nullptr;

TEST_F(DatabaseTest, QueryTest) {
  auto result = db_->Query("SELECT * FROM users");
  EXPECT_FALSE(result.empty());
}
```

---

## Troubleshooting & Tips

### Common Issues

- **Tests still run slowly:** Check if per-test setup is costly; move to per-suite setup.
- **Incorrect shard runs overlapping tests:** Confirm `GTEST_TOTAL_SHARDS` and `GTEST_SHARD_INDEX` are correctly set and match the test runner orchestration.
- **Non-deterministic test failures:** Use `--gtest_shuffle` and repeat runs to detect flakiness.
- **Memory/resource leaks between tests:** Avoid static or global mutable state unless carefully reset.

### Best Practices

- Always name test suites and tests without underscores to avoid naming conflicts.
- Prefer `nullptr` over `NULL` for pointer checks in assertions.
- When using shared fixtures with inheritance, ensure proper chaining of `SetUp()` and `TearDown()`.
- Use DISABLED_ prefix only temporarily; track disabled tests as tech debt.

### Performance Considerations

- Running tests in parallel relies on independent test cases. Avoid shared mutable global state.
- Use value-parameterized and typed tests to cut down on boilerplate and compilation overhead.
- Profile test suite duration with XML/JSON reports to identify bottlenecks.

### Alternative Approaches

- Use mock objects to replace slow dependencies.
- Split huge test files into smaller test suites for better parallelism.
- Configure CI infrastructure to maximize parallel worker count while avoiding resource contention.

---

## Next Steps & Related Content

- Explore [Test Organization](../guides/best-practices-patterns/test-organization) for structuring tests for scalability.
- Learn about [Parameterized and Typed Tests](../guides/core-testing-workflows/advanced-parameterized-tests) to reduce code duplication.
- Consult [Death Tests](../guides/core-testing-workflows/death-testing) for crash validation which also affects test speed.
- For build integration and automation, see [Build System Integration](../overview/audience-usecases-integration/integration-points).


---

# Summary

This guide covers practical techniques to improve GoogleTest suite performance by enabling parallel execution through sharding, reusing expensive fixture setups, and minimizing unnecessary test work. It offers step-by-step instructions, code examples, and best practices to optimize test runtime especially for large-scale projects.

**Key Sections:**
- Parallel Test Execution
- Reusing Test Fixtures
- Minimizing Test Overhead
- Troubleshooting and Tips
- Next Steps and Related Content

**Important Links:**
- [GoogleTest Primer](primer.md) (for basic concepts and test writing)
- [Advanced GoogleTest Topics](advanced.md) (for in-depth fixture reuse and test customization)
- [Parameterized and Typed Tests](guides/core-testing-workflows/advanced-parameterized-tests) (to reduce redundancy)
- [Test Organization Guide](guides/best-practices-patterns/test-organization)
- [Build and CI Integration](overview/audience-usecases-integration/integration-points)

**Action Items:**
- Start by enabling sharding to leverage parallelism.
- Adjust your fixtures to use suite-level setup/teardown.
- Incorporate parameterized tests to streamline repetitive cases.
- Use test shuffling and repeats for flakiness detection.
- Monitor test suite execution times using the XML/JSON reporting feature.
