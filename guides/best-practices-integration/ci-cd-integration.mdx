---
title: "Integrating with CI/CD Pipelines"
description: "How to automate test execution as part of continuous integration. Focuses on scripting, reporting, platform-specific setup, and ensuring test reliability in team environments."
---

# Integrating with CI/CD Pipelines

Automating the execution of your GoogleTest and GoogleMock tests within continuous integration (CI) and continuous deployment (CD) pipelines is essential for maintaining high-quality, reliable software. This guide walks you through practical strategies for scripting test execution, generating reports, configuring platform-specific environments, and ensuring test reliability in shared team environments.

---

## Workflow Overview

- **Task Description:**
  Learn how to incorporate GoogleTest-based tests into automated CI/CD pipelines to run tests consistently, report results, and manage environment-specific configurations.

- **Prerequisites:**
  - GoogleTest and GoogleMock built and linked properly in your project.
  - Familiarity with writing GoogleTest tests and using `RUN_ALL_TESTS()`.
  - Access to your CI/CD environment where tests will be executed.
  - Basic understanding of scripting and environment variable configuration.

- **Expected Outcome:**
  - Automated test runs triggered by your CI/CD system.
  - Test results logged and exported in formats consumable by CI dashboards.
  - Reliable, platform-aware execution scripts.
  - Best practices to minimize flaky tests and maximize meaningful reports.

- **Time Estimate:** 30 to 60 minutes for initial integration setup, depending on CI environment.

- **Difficulty Level:** Intermediate

---

## Step-by-Step Instructions

### 1. Write Your Tests with Automation in Mind

- Use the standard GoogleTest macros (`TEST()`, `TEST_F()`, `TEST_P()`, etc.) and ensure your tests return reliable pass/fail status.
- Implement any necessary setup and teardown logic inside fixtures or global test environments (`::testing::Environment`).
- Avoid manual user input or environment dependencies in tests.


### 2. Create or Use a `main()` Function to Run Tests

By default, GoogleTest provides a `gtest_main` library that includes a suitable `main()` function. If you require custom initialization (e.g., to configure test environments or parse additional arguments), write your own `main()` as:

```c++
#include <gtest/gtest.h>

int main(int argc, char** argv) {
  testing::InitGoogleTest(&argc, argv);
  return RUN_ALL_TESTS();
}
```

This program:

- Initializes GoogleTest, parsing command-line flags.
- Runs all registered tests.
- Returns 0 if all tests pass, non-zero otherwise (critical for CI success/failure detection).


### 3. Script Test Execution in Your CI Environment

Write a shell or batch script that your CI system will invoke. A typical script sequence includes:

- Building your test executable using CMake, Bazel, or your chosen build tool.
- Executing the test binary with GoogleTest flags.

Example bash script snippet:

```bash
#!/bin/bash

# Build tests
cmake --build build_dir --target your_test_target

# Run tests with XML output for CI reporting
./build_dir/your_test_binary --gtest_output=xml:test_results.xml

# Capture exit code
exit_code=$?

# Exit with same code so CI recognizes success/failure
exit $exit_code
```


### 4. Generate Test Reports in CI-Compatible Formats

GoogleTest supports outputting detailed test results in XML and JSON formats. This is essential for CI systems such as Jenkins, GitLab CI, CircleCI, or others to consume and display results.

- Use the `--gtest_output` flag:
  - `--gtest_output=xml:path/to/report.xml` generates an XML report compatible with JUnit-style reporting.
  - `--gtest_output=json:path/to/report.json` creates a JSON report.

Example command:

```bash
./your_test --gtest_output=xml:reports/results.xml
```


### 5. Configure Test Selection and Filtering

CI workflows often need to run a subset of tests or rerun flaky tests selectively.

- Use `--gtest_filter` to specify which tests to run.
- Use `--gtest_repeat=N` to repeat tests multiple times to detect flakiness.
- Use `--gtest_break_on_failure` during debugging to halt on first failure.

Example:

```bash
./your_test --gtest_filter=MyTestSuite.* --gtest_repeat=10
```


### 6. Handle Platform-Specific Setup

Ensure your CI environment prepares any platform-specific dependencies or configurations:

- Initialize environment variables.
- Prepare mock servers or dependencies.
- Use GoogleTest's cross-platform support to adjust behavior if needed via macros or runtime checks.

For embedded or specialized environments (e.g., ESP8266, Arduino), use the provided GoogleMock setup hooks such as `setup()` and `loop()` functions as in [gmock_main.cc](googlemock/src/gmock_main.cc).


### 7. Minimize Flaky Tests and Ensure Reliability

- Use `GTEST_SKIP()` for tests that cannot run in certain environments.
- Avoid shared state between tests or use `SetUpTestSuite()`/`TearDownTestSuite()` for shared fixtures.
- Shuffle tests with `--gtest_shuffle` to catch order dependencies.
- Use `--gtest_repeat` to detect intermittent failures.

---

## Examples

### Example: Running Tests with XML Output in a Shell Script

```bash
#!/bin/bash

# Build
cmake --build build_dir

# Run tests with XML report
./build_dir/test_binary --gtest_output=xml:build/reports/test_results.xml

# Return test status so CI captures pass/fail
exit $?
```

### Example: Custom main() Including a Global Test Environment

```c++
class MyGlobalEnvironment : public ::testing::Environment {
 public:
  void SetUp() override {
    // Initialize resources used by multiple tests
  }
  void TearDown() override {
    // Cleanup
  }
};

int main(int argc, char** argv) {
  testing::InitGoogleTest(&argc, argv);
  ::testing::AddGlobalTestEnvironment(new MyGlobalEnvironment());
  return RUN_ALL_TESTS();
}
```

### Example CI YAML Snippet (GitHub Actions)

```yaml
name: C++ Tests

on: [push, pull_request]

jobs:
  build-and-test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Setup CMake
      uses: jwlawson/actions-setup-cmake@v1
    - name: Build
      run: |
        cmake -S . -B build
        cmake --build build
    - name: Run tests
      run: |
        ./build/your_test --gtest_output=xml:build/test_results.xml
```

---

## Troubleshooting & Tips

### Common Issues

- **Test executable not found or fails to run:**
  - Verify the test executable path in your CI script.
  - Ensure all dependencies and runtime libraries are available.

- **Tests fail to report to CI dashboards:**
  - Confirm report files are written to expected paths.
  - Use absolute paths if relative paths cause confusion.

- **Flaky or intermittent test failures:**
  - Use `--gtest_repeat` to reproduce.
  - Shuffle test order with `--gtest_shuffle`.
  - Investigate access to shared or global state.

- **Tests depending on environment variables:**
  - Set environment variables explicitly in CI job configurations.

### Best Practices

- Use `gtest_output=xml` to produce reports that most CI systems support.
- Leverage filtering flags to run only relevant tests for a given pipeline stage.
- Keep test execution fast and isolated to reduce CI cycle times.
- Use explicit test naming and suites to organize large tests for better filtering.
- Link with `gmock_main` or provide your own main as appropriate.
- Use `AddGlobalTestEnvironment` for setup/tear-down that spans all tests.

---

## Next Steps & Related Content

- Explore [Test Discovery and Execution](guides/essential-workflows/test-discovery-execution.md) for filtering and parallel runs.
- Learn [Configuring GoogleTest in Your Project](getting-started/configuration-troubleshooting/configuration-basics.md) for build integration.
- Deep dive into [Debugging and Troubleshooting Test Failures](guides/best-practices-integration/debugging-and-troubleshooting.md) to handle flakiness and errors.
- Review the [GoogleTest Primer](docs/primer.md) if you are new to writing tests.
- Check out the [googlemock_main.cc](googlemock/src/gmock_main.cc) source for platform-specific test main implementations.

---

By following this guide, you will automate your testing workflow confidently, ensuring consistent quality and rapid feedback within your development pipelines.
