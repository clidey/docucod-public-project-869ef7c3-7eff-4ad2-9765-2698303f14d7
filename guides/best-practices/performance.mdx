---
title: "Test Performance & Debugging"
description: "Strategies for faster test execution, identifying bottlenecks, and debugging failures effectively using GoogleTest and GoogleMock tools."
---

# Test Performance & Debugging

## Overview

This guide helps you enhance your testing workflow by focusing on strategies to speed up test execution, identify bottlenecks, and effectively debug failures using GoogleTest and GoogleMock tools. Whether you have a massive test suite or encounter intermittent failures, these practices empower you to maintain fast feedback loops and reliable tests.

## 1. Speeding Up Test Execution

### 1.1 Selective Test Running

Use filtering options to run only specific tests or test suites, reducing execution time during development:

- **Command-line flag:** Use `--gtest_filter` to specify which tests to run.

```bash
./test_binary --gtest_filter=MyTestSuite.MyTest
```

- **Environment variable:** Set `GTEST_FILTER` similarly.

**Example:**

```bash
./test_binary --gtest_filter=* -MyTestSuite.SlowTest
```
Runs all tests except the slow ones.

### 1.2 Disabling Broken or Long-Running Tests Temporarily

Prefix a test or test suite name with `DISABLED_` to exclude it from runs without removing or commenting it out.

```cpp
TEST(MyTestSuite, DISABLED_SkipThisTest) { ... }
```

Use `--gtest_also_run_disabled_tests` to run them explicitly when needed.

### 1.3 Test Sharding

To distribute tests across multiple machines or processes, use sharding via environment variables:

- `GTEST_TOTAL_SHARDS`: Total number of shards.
- `GTEST_SHARD_INDEX`: Index of the current shard (0-based).

GoogleTest will execute only the subset of tests assigned to each shard, allowing parallelization.

### 1.4 Running Tests Multiple Times

Use the `--gtest_repeat=N` flag to run all or filtered tests multiple times. This helps detect flaky tests.

```bash
./test_binary --gtest_repeat=100
```

Pair with `--gtest_break_on_failure` to stop at the first failure for interactive debugging.

### 1.5 Test Execution Shuffle

To detect hidden test dependencies, run tests in a randomized order:

```bash
./test_binary --gtest_shuffle
```

Control the seed with `--gtest_random_seed=SEED` for reproducibility.

## 2. Identifying Performance Bottlenecks

### 2.1 Measuring Test Duration

By default, GoogleTest reports the elapsed time for each test. Use this data to identify slow tests.

### 2.2 Recording Custom Performance Metrics

Use `RecordProperty()` within tests to log additional data, which appears in XML and JSON reports.

```cpp
TEST(PerformanceTest, MeasureDuration) {
  auto duration_ms = RunExpensiveOperation();
  ::testing::Test::RecordProperty("DurationMs", duration_ms);
  EXPECT_LT(duration_ms, 200);
}
```

Later, aggregate and analyze these properties for bottlenecks.

### 2.3 Skipping Expensive Tests

Use the `GTEST_SKIP()` macro to skip tests conditionally at runtime based on the environment or resource availability:

```cpp
TEST(SlowTest, SkipIfNotOnPowerfulMachine) {
  if (!IsPowerfulMachine()) {
    GTEST_SKIP() << "Skipping slow test on this machine.";
  }
  // Run slow test
}
```

## 3. Debugging Failures Effectively

### 3.1 Verbose Output

Run tests with increased verbose logging to capture detailed context for failures:

```bash
./test_binary --gtest_verbose=info
```

### 3.2 Using SCOPED_TRACE for Context

Add `SCOPED_TRACE()` around blocks or loops when subroutines contain assertions to surface detailed tracebacks and pinpoint failure locations:

```cpp
SCOPED_TRACE("Iteration " + std::to_string(i));
EXPECT_EQ(Process(i), expected_value);
```

This trace information is attached to failure messages, improving understandability.

### 3.3 Catching Fatal Failures in Subroutines

Understand that fatal assertions abort only the current function, not the entire test. To ensure fatal failures propagate as expected, use:

- `ASSERT_NO_FATAL_FAILURE()` or `EXPECT_NO_FATAL_FAILURE()` around subroutine calls
- `HasFatalFailure()` to check if a fatal failure occurred and bail out early

Example:

```cpp
Subroutine();
if (::testing::Test::HasFatalFailure()) return;
// Continue if no fatal failure
```

Alternatively, enable exception throwing on failures using a custom listener if your environment supports exceptions.

### 3.4 Logging Additional Information

Use streaming messages on assertions to provide detailed failure context:

```cpp
EXPECT_EQ(x, y) << "x and y differ for inputs: " << input_details;
```

You can also use `RecordProperty()` to log key-values for failed tests.

### 3.5 Debugging Death Tests

Death tests verify program behaviors that cause termination. Focus on these points:

- Keep death test code isolated and minimal.
- Beware of side effects as death tests run in child processes; changes do not propagate to the parent process.
- Use `ASSERT_DEATH` or `EXPECT_DEATH` macros with regex matchers to assert on expected crash behavior.

For more, see [Death Tests](advanced.md#death-tests).

## 4. Advanced Debugging Techniques

### 4.1 Asserting on Failures (Testing the Testing Framework)

To verify that code triggers failures as expected, use macros from `gtest/gtest-spi.h`:

- `EXPECT_FATAL_FAILURE(statement, substring);`
- `EXPECT_NONFATAL_FAILURE(statement, substring);`

These check that the statement generates expected failure messages.

### 4.2 Event Listeners

Extend GoogleTest behavior by implementing custom event listeners to monitor test start/end, failures, or write logs. This can be critical for integrating with external tools or generating custom reports.

### 4.3 Analyzing Test Output Logs

Separate GoogleTest output and your component logs by redirecting:

```bash
./test_binary > gtest_output.txt 2> component_logs.txt
```

GoogleTest writes test results to stdout by default, helping clarity.

## 5. Best Practices for Test Performance & Debugging

- **Isolate slow or flaky tests:** Disable or shard them during iterative development.
- **Use parameterized tests:** Reuse the same test logic with different inputs efficiently.
- **Leverage test fixtures:** Share expensive setup and teardown via `SetUpTestSuite()` and `TearDownTestSuite()` to avoid repeated initialization cost.
- **Apply `SCOPED_TRACE` in complex test code:** This simplifies correlating failure points with input data or loop iterations.
- **Monitor and tune test parallelism:** Combine sharding with parallel test runners.
- **Avoid side effects in tests, especially in death tests:** Aim for deterministic, reproducible test behavior.

## 6. References & Additional Resources

- [GoogleTest Advanced Topics](advanced.md) — for deep dives into assertions, death tests, and resource sharing
- [GoogleTest FAQ](faq.md) — answers common questions related to test failures and debugging
- [gMock for Dummies](gmock_for_dummies.md) — for integrating mocks with your debugging workflow
- [GoogleTest Primer](primer.md) — foundational concepts on writing and structuring tests

---

> This page is part of the larger GoogleTest documentation suite. For installation, setup, and introductory topics, consider reviewing the Getting Started and Primer guides before applying these advanced performance and debugging strategies.
