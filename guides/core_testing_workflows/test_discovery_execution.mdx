---
title: "Test Discovery and Execution"
description: "Explains how GoogleTest automatically discovers and runs your tests, including how to execute test binaries, use test filters, and interpret test output. Provides tips on structuring test code for maintainability."
---

# Test Discovery and Execution

GoogleTest automatically finds and runs all your tests without manual registration. This guide walks you through executing test binaries, filtering which tests to run, interpreting test outputs, and structuring your test code for maintainability.

---

## 1. Understanding Test Discovery in GoogleTest

When you compile a GoogleTest-based project, all test cases you define using macros like `TEST()` and `TEST_F()` are automatically registered behind the scenes. You don't need to manually register tests. GoogleTest's test runner will discover these tests at runtime by examining the linked test binaries.

This automatic discovery relies on each `TEST()` macro creating a test fixture and registering it.

> **Why this matters to you:** No extra bookkeeping is needed to manage test registration. Your focus remains on writing tests.

---

## 2. Executing Your Test Suite

### Running the Test Binary

Once your tests are compiled into an executable, running the binary will execute all discovered tests.

```bash
./your_test_binary
```

**Expected outcome:**
- The test runner executes all registered test cases.
- The console outputs the status for each test: `[  PASSED  ]` or `[  FAILED  ]`.
- A final summary displays the number of tests run and any failures.

### Using `RUN_ALL_TESTS()` Macro

Your test program should call `RUN_ALL_TESTS()` usually inside `main()`. This function performs the actual test execution.

```cpp
int main(int argc, char **argv) {
  testing::InitGoogleTest(&argc, argv);
  return RUN_ALL_TESTS();
}
```

If you skip `RUN_ALL_TESTS()`, no tests are run!

---

## 3. Filtering and Selecting Tests to Run

Sometimes you want to run only a subset of tests.

### `--gtest_filter` Command Line Flag

You can specify which tests to run using wildcards matching test case and test names:

```bash
./your_test_binary --gtest_filter=MySuite.*       # All tests in MySuite
./your_test_binary --gtest_filter=*.TestName       # All tests named TestName
./your_test_binary --gtest_filter=MySuite.TestName # The single test MySuite.TestName
./your_test_binary --gtest_filter=-MySuite.TestName # Run all except this test
```

**Pro tip:** Combine positive and negative filters with a colon separator:

```bash
./your_test_binary --gtest_filter=MySuite.*:-MySuite.FlakyTest
```

### Other Selection Flags

- `--gtest_list_tests`: Lists all available tests so you can pick which to run.

```bash
./your_test_binary --gtest_list_tests
```

Output example:

```
MySuite.
  TestOne
  TestTwo
OtherSuite.
  TestA
```

---

## 4. Interpreting Test Output

The test runner console output provides detailed reports:

- Each line beginning with `[ RUN      ]` shows a test starting.
- Lines with `[       OK ]` indicate the test passed.
- Lines with `[  FAILED  ]` indicate a failure.
- A summary at the end shows total tests run, passed, and failed.

If a test fails, GoogleTest provides:
- The file and line number where the failure occurred.
- A description of the failed assertion.
- Optionally, the stack trace if enabled.

You can redirect output to a file for later examination:

```bash
./your_test_binary > test_results.log
```

---

## 5. Best Practices: Structuring Test Code for Maintainability

The way you organize your tests can influence ease of use and clarity.

### Organize Tests into Suites and Fixtures

Group logically related tests using `TEST_F()` with test fixtures.

```cpp
class MyClassTest : public ::testing::Test {
 protected:
  void SetUp() override {
    // Initialization code
  }

  void TearDown() override {
    // Cleanup code
  }

  MyClass instance_;
};

TEST_F(MyClassTest, DoesThis) {
  EXPECT_EQ(instance_.DoSomething(), expected_value);
}
```

Fixtures let you share setup and teardown code across tests.

### Keep Tests Focused and Independent

Each test should verify one specific behavior and run independently.

### Use Meaningful Test and Suite Names

Explicit names help understanding and filtering.

### Consider Test Execution Order

Avoid dependencies on test execution order. GoogleTest runs tests in unspecified order.

---

## 6. Tips and Troubleshooting

<Tip>
If your test binary runs no tests, verify you have `RUN_ALL_TESTS()` in your `main()` function and that test cases are correctly defined with `TEST` or `TEST_F` macros.
</Tip>

<Tip>
Use `--gtest_list_tests` to confirm which tests GoogleTest discovered.
</Tip>

<Warning>
Expectations must be set before invoking any mock methods. Setting expectations after mock calls leads to undefined behavior.
</Warning>

<Note>
If your test output is too verbose or hard to read, you can control verbosity using flags like `--gtest_brief=1` to reduce output.
</Note>

---

## 7. Summary

GoogleTest simplifies test discovery and execution through automatic test registration in compiled binaries. Running the test binary executes all tests; filtering options and detailed output make managing large test suites feasible. Structuring tests with fixtures and meaningful names promotes maintainability. For mocking-related test writing, consider exploring [Using GoogleMock](./using_googlemock) guide.

---

## 8. Additional Resources

- [GoogleTest Primer](overview/product-intro-core-concepts/core-concepts-terminology)
- [Writing Your First Test](guides/core_testing_workflows/writing_first_test)
- [Running and Validating Tests](getting-started/first-steps-with-tests/running-tests)
- [Using GoogleMock](guides/core_testing_workflows/using_googlemock)
- [Troubleshooting Common Issues](getting-started/troubleshooting-validation/common-issues)

---

## 9. Diagram: Test Discovery and Execution Flow

```mermaid
flowchart TD
  Start([Run Test Binary]) --> Discover[Test Discovery]
  Discover --> RunAllTests[Call RUN_ALL_TESTS()]
  RunAllTests --> Execute[Execute All Tests]
  Execute --> Output[Show Test Results]
  Output --> End([Finish])

  subgraph Test Filtering
    FiltFilter[Use --gtest_filter]
    RunAllTests --> FiltFilter
    FiltFilter --> Execute
  end
```
