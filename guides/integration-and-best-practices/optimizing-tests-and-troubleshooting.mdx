---
title: "Optimizing Test Performance and Troubleshooting"
description: "Learn best practices for fast, stable tests—including parallelism, test design patterns, debugging failing tests, and utilizing GoogleTest's reporting and diagnostic features to resolve problems quickly."
---

# Optimizing Test Performance and Troubleshooting

## Introduction

This guide focuses on best practices to achieve fast, stable, and maintainable tests using GoogleTest. It covers essential techniques such as leveraging parallel test execution, applying effective test design patterns, debugging failing tests efficiently, and harnessing GoogleTest’s rich reporting and diagnostic tools. By integrating these strategies, you will minimize test run times, produce reliable results, and resolve issues quickly.

---

## 1. Enhancing Test Performance

### 1.1 Parallel Test Execution (Parallelism)

GoogleTest supports running multiple tests concurrently to reduce overall test time, especially useful for large test suites.

#### How to Enable Parallelism

- Use external test runners or build tools (e.g., Bazel, CTest) with parallel execution options.
- GoogleTest itself supports sharding by environment variables which split tests across processes/machines.

##### Setting up Sharding:

1. Set `GTEST_TOTAL_SHARDS` to the total number of shards (parallel test runners).
2. Set `GTEST_SHARD_INDEX` to the index of the current shard (zero-based).

Only tests belonging to the specified shard will run, distributing workload evenly.

#### Best Practices

- Ensure tests are independent and do not share mutable global state.
- Use test fixtures carefully; remember that each test creates a fresh fixture instance.
- Avoid dependencies on order or side effects between tests.

> <Tip>
> Running tests in parallel maximizes hardware utilization and cuts down build feedback loops.
> </Tip>

### 1.2 Speeding Up Tests Using Shared Resources

- Utilize *test fixtures* (`TEST_F`) to initialize reusable objects once per test.
- For expensive resources, leverage **per-test-suite** setup/teardown (`SetUpTestSuite()` and `TearDownTestSuite()`) to avoid repeated costly initialization.

Example:

```c++
class DatabaseTest : public ::testing::Test {
 protected:
  static void SetUpTestSuite() {
    // Initialize shared database connection
  }

  static void TearDownTestSuite() {
    // Cleanup shared database connection
  }

  void SetUp() override {
    // Setup per-test data
  }

  void TearDown() override {
    // Cleanup per-test data
  }
};
```

> <Warning>
> Shared state must be immutable or reset properly between tests to guarantee independence.
> </Warning>

---

## 2. Designing Tests for Stability and Maintainability

### 2.1 Follow Test Independence and Repeatability

- Tests should not depend on other tests or shared mutable state.
- Reset or reinitialize state in each test’s `SetUp()` or by using fresh test fixtures.

### 2.2 Use Well-Defined Test Suites and Fixtures

- Group logically related tests using *test suites* (`TEST` macros share the same suite name).
- Share reusable code and objects in fixtures with `TEST_F`.

### 2.3 Naming Conventions

- Name test suites and tests clearly, following [Google C++ Style Guide function naming](https://google.github.io/styleguide/cppguide.html#Function_Names).
- Avoid underscores in test and test suite names.

### 2.4 Apply Appropriate Assertions

- Use `EXPECT_*` when you want tests to continue after a failure.
- Use `ASSERT_*` when the failure should abort the current test function immediately.

> <Tip>
> Combine assertions with custom failure messages to clarify errors:
> ```c++
> ASSERT_EQ(v1, v2) << "Values differ at step 3";
> ```
> </Tip>

---

## 3. Debugging Failing Tests Effectively

### 3.1 Isolate and Reproduce Failures

- Run a single test by filtering with `--gtest_filter=TestSuite.TestName`.
- Use `RUN_ALL_TESTS()`’s return code to detect failures programmatically.

### 3.2 Use GoogleTest’s Failures and Logs

- GoogleTest reports failures with file and line numbers.
- Capture additional diagnostic info by streaming messages into assertions.

Example:

```c++
EXPECT_EQ(actual, expected) << "Mismatch in iteration " << i;
```

### 3.3 Employ `SCOPED_TRACE` for Better Context

Add contextual trace information in nested calls to help locate failures in complex test flows.

```c++
SCOPED_TRACE("Iteration " + std::to_string(i));
MySubTest(i);
```

### 3.4 Leveraging Death Tests

- Use death tests to verify that code terminates as expected under error conditions.
- Name test suites with `*DeathTest` suffix.

### 3.5 Catching Failures in Subroutines

- Use `ASSERT_NO_FATAL_FAILURE()` and `EXPECT_NO_FATAL_FAILURE()` macros when calling subroutines that use fatal assertions to prevent false positives.

Example:

```c++
ASSERT_NO_FATAL_FAILURE(SubroutineTest());
```

> <Note>
> Fatal assertions abort only the current function, not the entire test.
> </Note>

---

## 4. Leveraging GoogleTest Reporting and Diagnostic Features

### 4.1 Verbosity Levels

Set the verbosity of GoogleTest and GoogleMock output using flags to get more detailed logs:

- `--gtest_verbose=info` – detailed logs on expected/unexpected calls
- `--gtest_verbose=warning` – warnings on suspicious calls
- `--gtest_verbose=error` – only errors

### 4.2 Generating Reports

- Use `--gtest_output=xml:path/to/output.xml` to generate JUnit-compatible XML reports.
- Use `--gtest_output=json:path/to/output.json` for JSON reports.

These reports integrate with CI systems and reporting tools.

### 4.3 Filtering and Running Subsets

Control which tests to run using:

- `--gtest_filter=PositivePattern[-NegativePattern]`

Example:

```bash
./test_binary --gtest_filter=FactorialTest.*-FactorialTest.HandsZeroInput
```

### 4.4 Skipping Tests

- Use `GTEST_SKIP()` to skip tests conditionally during runtime with optional messages.

Example:

```c++
TEST(MyTestSuite, PossiblySkip) {
  if (!IsFeatureSupported()) {
    GTEST_SKIP() << "Feature not enabled";
  }
  ... test body ...
}
```

### 4.5 Customizing Test Events

GoogleTest’s event listener API allows you to customize test progress output or integrate with other systems. You can:

- Add custom listeners to handle test start/end, failures, and more.
- Replace or suppress default output with specialized reporting.

See the [Advanced Guide - Event Listeners](advanced.md#extending-google-test-by-handling-test-events) for details.

---

## 5. Troubleshooting Common Issues

### 5.1 Test Failures with Unexpected Results

- Verify your test assertions match the expected behavior.
- Use detailed failure messages and value printing to pinpoint issues.

### 5.2 Uninteresting or Unexpected Mock Calls

- Use `EXPECT_CALL` to specify expected interactions.
- Use `ON_CALL` to set default behaviors to avoid warnings about uninteresting calls.

### 5.3 Managing Test Dependencies

- Avoid shared mutable global states.
- Ensure fixtures clean up resources to prevent leaks or side effects.

### 5.4 Handling Slow Tests

- Profile tests to identify and optimize bottlenecks.
- Use `SetUpTestSuite()` to share expensive setup.

### 5.5 Dealing with Flaky Tests

- Leverage `--gtest_repeat=N` to repeatedly run tests and catch intermittent failures.
- Use parallel execution with sharding to isolate flaky behavior.

### 5.6 Common Build and Integration Problems

Refer to [Common Setup Issues & Solutions](getting-started/troubleshooting-faq/common-setup-issues.mdx) for detailed guidance on integrating GoogleTest and GoogleMock in your build system and environment.

---

## 6. Summary & Next Steps

By applying the techniques in this guide, you will build C++ test suites that run efficiently and reliably. Mastering parallelism, effective test design, and GoogleTest's diagnostic capabilities ensures rapid feedback and easier maintenance.

### Next Steps:

- Explore [GoogleTest Advanced](advanced.md) to deepen your testing skills with sophisticated assertions and test environment controls.
- Dive into [Setting Up Expectations and Actions](guides/mocking-and-advanced-scenarios/setup-expectations-actions.mdx) for advanced mocking strategies.
- Learn best practices on [Organizing and Running Test Suites](guides/core-testing-workflows/organizing-and-running-tests.mdx).

---

## References

- [GoogleTest Primer](primer.md) - Basics of writing tests.
- [Advanced GoogleTest Topics](advanced.md) - Deep dive into GoogleTest power features.
- [Mocking Reference](docs/reference/mocking.md) - Details on mocking APIs.
- [Common Setup Issues](getting-started/troubleshooting-faq/common-setup-issues.mdx) - Troubleshooting build and runtime issues.
- [Running Tests & Interpreting Output](getting-started/configuring-using-tests/running-tests-validate-output.mdx) - Practical test execution tips.
